{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375dadd1",
   "metadata": {},
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05c38e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "print_figs = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6977239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# model specs\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='VAE MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=30, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--no-accel', action='store_true', \n",
    "                    help='disables accelerator')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "# Decide which device we want to run on (CUDA > MPS > CPU)\n",
    "if torch.cuda.is_available() and ngpu > 0:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device.type in [\"cuda\", \"mps\"] else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../../datasets', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../../datasets', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82127b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2cd19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "    return avg_loss  \n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         '../../../datasets/results/VAE_MNIST/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59c7f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255eda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 550.815796\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 306.415344\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 238.970428\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 219.622406\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 214.331833\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 208.944855\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 206.190445\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 195.811539\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 196.140961\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 193.512360\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 182.127335\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 176.475739\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 185.079376\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 170.465424\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 168.447723\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 163.081894\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 163.014450\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 152.732758\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 158.169296\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 154.928299\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 155.935196\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 153.202606\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 154.646820\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 146.365265\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 143.468552\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 146.300751\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 146.816483\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 146.849213\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 138.062805\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 143.912079\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 140.501129\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 136.203674\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 143.104324\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 142.987152\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 143.589005\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 136.875534\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 142.471497\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 133.860107\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 133.645004\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 131.763397\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 132.458527\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 130.793121\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 133.248337\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 127.198647\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 137.847061\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 131.028549\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 133.806747\n",
      "====> Epoch: 1 Average loss: 165.7391\n",
      "====> Test set loss: 128.4992\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 124.679268\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 123.585175\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 126.442436\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 130.465683\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 130.380463\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 131.910278\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 127.475883\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 127.134834\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 128.246384\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 124.309959\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 125.761856\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 122.294991\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 128.969147\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 124.247284\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 125.212128\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 123.427505\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 123.947769\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 120.730843\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 121.601280\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 120.805954\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 120.920380\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 116.798790\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 120.622009\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 120.182106\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 114.156631\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 120.812126\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 116.408676\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 121.312263\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 119.475052\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 122.119278\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 117.217178\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 118.903709\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 121.112015\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 122.255417\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 117.409065\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 121.162743\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 120.795105\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 117.732956\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 120.166718\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 113.241486\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 119.066742\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 116.523987\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 117.279961\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 116.472328\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 117.543640\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 117.382782\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 116.605896\n",
      "====> Epoch: 2 Average loss: 121.6607\n",
      "====> Test set loss: 115.7584\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 120.124176\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 116.322632\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 117.469002\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 119.853554\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 117.719368\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 115.290283\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 115.488800\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 117.286095\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 116.288246\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 115.465843\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 115.326599\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 122.377045\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 116.875961\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 114.820374\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 117.366226\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 111.209076\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 115.937431\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 108.128571\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 114.562675\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 114.958984\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 114.358604\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 114.014015\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 112.069260\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 115.791443\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 113.697807\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 110.778992\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 115.763123\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 113.123116\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 114.916641\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 116.565750\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 114.123779\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 110.665634\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 111.477798\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 109.974426\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 117.422195\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 110.360657\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 111.432343\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 110.538490\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 112.703392\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 114.061867\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 116.125618\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 111.283760\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 111.698921\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 111.403824\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 110.546326\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 112.956459\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 113.399139\n",
      "====> Epoch: 3 Average loss: 114.6617\n",
      "====> Test set loss: 111.8722\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 120.483322\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 113.731766\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 115.497437\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 111.542725\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 114.969109\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 115.840012\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 115.252975\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 111.134430\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 111.298302\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 109.951744\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 114.880585\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 108.821259\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 112.758865\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 109.147919\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 110.579178\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 109.668755\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 111.936142\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 113.714127\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 109.056229\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 114.283508\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 108.455856\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 110.244339\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 108.382416\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 111.985184\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 112.100098\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 115.588867\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 114.227234\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 105.522995\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 110.550812\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 111.612938\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 109.441040\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 109.511009\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 111.312813\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 114.121841\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 111.023605\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 114.990967\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 111.392296\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 111.535820\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 110.245148\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 110.677910\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 111.324226\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 111.291039\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 110.429237\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 107.993584\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 106.252502\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 108.525612\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 112.858910\n",
      "====> Epoch: 4 Average loss: 111.7514\n",
      "====> Test set loss: 109.8106\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 107.225952\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 111.473396\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 110.306122\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 109.809364\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 106.868774\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 108.395035\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 108.783455\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 111.724327\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 112.417618\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 110.114380\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 113.838722\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 106.905716\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 113.353714\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 111.200638\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 107.968315\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 109.056183\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 107.094322\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 107.231499\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 113.994156\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 108.067497\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 113.105667\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 108.629845\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 108.474457\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 105.728271\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 105.788750\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 109.252075\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 113.724785\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 112.033188\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 111.870636\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 111.825478\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 110.898804\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 111.251640\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 107.943672\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 110.777176\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 108.117607\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 107.284180\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 108.919006\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 108.508614\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 116.312675\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 110.048920\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 113.756950\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 107.515045\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 107.879440\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 109.350464\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 110.286285\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 109.129242\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 113.436729\n",
      "====> Epoch: 5 Average loss: 109.9989\n",
      "====> Test set loss: 108.4354\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 107.382523\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 106.344093\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 111.980713\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 108.505493\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 105.959366\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 108.642204\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 113.694839\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 108.176453\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 113.280136\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 108.323753\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 107.090668\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 113.175079\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 103.716179\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 109.181519\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 107.548538\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 107.940994\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 108.167953\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 109.074127\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 104.004242\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 108.442780\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 104.277603\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 108.686798\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 110.418236\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 110.899323\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 113.423653\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 111.325882\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 109.863312\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 110.331131\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 105.803291\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 105.718147\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 111.793274\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 108.655273\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 110.442764\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 113.588570\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 111.298775\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 105.902557\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 106.311928\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 107.201576\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 105.217720\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 106.189217\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 107.363617\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 109.522644\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 109.544975\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 109.151260\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 108.272423\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 111.195358\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 105.466644\n",
      "====> Epoch: 6 Average loss: 108.8148\n",
      "====> Test set loss: 107.6553\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 107.950378\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 107.828262\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 106.184753\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 104.276245\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 107.164108\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 107.689407\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 109.029617\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 105.716698\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 108.290855\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 107.857224\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 105.901901\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 110.050613\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 106.509499\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 109.846893\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 110.054321\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 109.490768\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 109.789825\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 107.775299\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 107.688232\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 109.807701\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 103.897942\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 105.428192\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 101.790268\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 108.669510\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 106.214874\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 107.278397\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 110.726761\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 109.265030\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 106.910995\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 107.769119\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 110.371605\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 106.118889\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 110.708191\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 109.513489\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 107.289726\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 107.800720\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 111.182610\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 108.032379\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 105.895317\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 107.113594\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 106.042778\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 105.769043\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 107.049980\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 110.544327\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 106.390045\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 108.042854\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 107.139252\n",
      "====> Epoch: 7 Average loss: 107.9181\n",
      "====> Test set loss: 107.1273\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 107.472595\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 106.507812\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 104.302589\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 105.267769\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 107.011459\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 107.135635\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 108.545242\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 104.265755\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 106.958633\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 108.741791\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 107.055779\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 102.538269\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 107.290428\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 108.813721\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 105.752213\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 111.345238\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 102.034988\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 105.527649\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 106.859329\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 108.261436\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 107.165886\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 106.974976\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 109.212898\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 103.535370\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 107.782333\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 108.723351\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 105.818321\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 109.387543\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 107.266762\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 104.906204\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 109.507309\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 108.118179\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 104.926392\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 111.179016\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 107.342331\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 103.316895\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 105.687500\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 106.597481\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 107.927872\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 106.074417\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 106.537704\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 104.578766\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 105.659546\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 103.758728\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 108.270721\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 106.843399\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 106.212967\n",
      "====> Epoch: 8 Average loss: 107.2660\n",
      "====> Test set loss: 106.5692\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 107.283279\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 103.029518\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 108.249138\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 102.261230\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 103.661613\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 107.136948\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 106.502640\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 106.150238\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 106.159126\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 110.699677\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 104.804520\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 104.782959\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 109.593750\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 107.506195\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 107.553268\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 107.501396\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 114.840721\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 109.495987\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 110.113968\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 104.474945\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 109.863693\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 105.927460\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 106.908875\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 105.044006\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 108.864090\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 107.664124\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 107.266403\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 101.968170\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 107.907906\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 109.381012\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 105.087280\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 106.165176\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 108.129921\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 107.593987\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 105.862267\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 103.646545\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 107.814964\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 107.345276\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 106.900719\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 106.339279\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 103.034332\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 104.226166\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 105.452133\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 101.564522\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 104.905396\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 108.910667\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 102.843422\n",
      "====> Epoch: 9 Average loss: 106.7604\n",
      "====> Test set loss: 105.8964\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 102.873589\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 105.959534\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 106.429245\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 106.934395\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 107.156952\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 107.146011\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 104.928268\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 106.062164\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 108.869247\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 103.939026\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 105.009155\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 107.644409\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 106.059448\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 109.101837\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 105.656540\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 106.697342\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 105.926544\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 106.838257\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 107.817932\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 105.899429\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 106.402596\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 102.517349\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 108.721840\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 106.938110\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 108.276749\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 108.494392\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 102.903145\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 109.245888\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 109.188751\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 106.383591\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 109.490364\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 106.401535\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 104.790527\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 108.192856\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 104.361389\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 109.110222\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 105.297523\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 107.943222\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 104.008553\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 107.204025\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 105.858246\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 108.230804\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 105.697449\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 106.553253\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 109.928925\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 112.072327\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 107.089539\n",
      "====> Epoch: 10 Average loss: 106.3252\n",
      "====> Test set loss: 105.5416\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 105.593063\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 106.422356\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 102.763382\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 107.301071\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 108.373306\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 108.199791\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 104.701736\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 110.165939\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 106.765739\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 103.131737\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 106.235413\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 106.657074\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 105.127060\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 105.339737\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 106.937607\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 105.615013\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 105.599174\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 108.007492\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 103.346176\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 106.190826\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 107.357574\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 107.977791\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 103.402016\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 103.987816\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 103.149239\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 103.754593\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 101.935715\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 103.462433\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 108.917091\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 104.595970\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 107.357880\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 106.366898\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 107.806824\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 107.640518\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 104.731430\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 106.237099\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 104.089920\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 106.429054\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 106.527100\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 107.990746\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 106.886375\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 104.318016\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 103.877930\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 105.385841\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 103.255806\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 107.662323\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 106.701118\n",
      "====> Epoch: 11 Average loss: 105.9566\n",
      "====> Test set loss: 105.5565\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 102.951324\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 107.030533\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 104.841400\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 108.359016\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 106.511436\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 105.616478\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 107.861923\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 107.064110\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 103.383095\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 107.139320\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 109.424057\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 108.511490\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 106.366928\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 107.015762\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 103.599716\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 103.308754\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 104.607956\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 104.587372\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 105.554955\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 105.398438\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 104.252426\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 107.381073\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 105.973549\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 106.956528\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 104.833076\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 102.380920\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 106.760796\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 104.964958\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 104.245338\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 105.960693\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 109.362106\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 111.105148\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 105.983604\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 107.380714\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 101.474258\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 102.855347\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 105.718948\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 107.486954\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 100.875992\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 108.259766\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 104.551704\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 106.816055\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 110.160995\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 97.543526\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 106.037781\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 105.677994\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 105.984917\n",
      "====> Epoch: 12 Average loss: 105.6420\n",
      "====> Test set loss: 105.0807\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 103.822670\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 101.722923\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 101.787582\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 104.222740\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 108.796524\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 108.927841\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 101.091614\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 103.456985\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 105.861252\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 107.278946\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 105.280876\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 107.220589\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 103.309326\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 106.376335\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 110.957733\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 108.174515\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 106.953606\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 106.280441\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 104.727646\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 108.139679\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 105.170349\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 109.213005\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 105.025192\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 107.200813\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 107.145508\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 105.369400\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 104.290939\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 102.301941\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 103.230408\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 105.709808\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 104.701614\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 104.874413\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 106.418953\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 106.464783\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 106.614792\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 106.952286\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 106.882111\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 108.215652\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 104.191216\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 114.267990\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 107.160294\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 106.960258\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 104.498169\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 102.837601\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 105.690140\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 104.127708\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 106.019714\n",
      "====> Epoch: 13 Average loss: 105.3133\n",
      "====> Test set loss: 104.8627\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 101.089012\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 108.233017\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 104.568176\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 103.739838\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 106.162216\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 103.959419\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 104.579849\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 106.121338\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 106.979790\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 105.417320\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 103.755707\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 106.976418\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 105.260483\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 103.635132\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 109.287567\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 107.528046\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 105.529373\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 107.778847\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 106.446510\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 101.776054\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 104.465652\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 107.970016\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 106.801270\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 100.680832\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 107.573578\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 105.949127\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 105.567406\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 101.880539\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 105.575073\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 102.529694\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 103.625809\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 102.448326\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 104.737991\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 110.067978\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 105.074127\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 102.976891\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 108.133011\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 105.265747\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 106.162872\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 108.595947\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 105.910645\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 101.935410\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 104.845657\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 105.398857\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 110.225044\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 104.862083\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 104.911972\n",
      "====> Epoch: 14 Average loss: 105.1180\n",
      "====> Test set loss: 104.8096\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 98.336067\n",
      "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 104.410843\n",
      "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 108.119408\n",
      "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 103.938766\n",
      "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 106.629982\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 105.010338\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 102.843430\n",
      "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 108.144844\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 104.056747\n",
      "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 107.724915\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 101.620232\n",
      "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 102.411606\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 105.074356\n",
      "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 104.647285\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 104.397720\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 102.284218\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 105.931862\n",
      "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 106.121094\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 106.228760\n",
      "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 104.089760\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 104.728500\n",
      "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 105.591614\n",
      "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 104.430695\n",
      "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 102.648895\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 101.144753\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 105.452072\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 103.008659\n",
      "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 106.074806\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 103.707306\n",
      "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 106.327499\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 104.611053\n",
      "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 103.570045\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 105.533554\n",
      "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 108.135437\n",
      "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 103.512527\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 106.996391\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 106.214203\n",
      "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 106.132851\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 106.651321\n",
      "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 103.153465\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 107.278763\n",
      "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 105.277084\n",
      "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 104.651207\n",
      "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 105.263840\n",
      "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 103.409088\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 105.151642\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 110.797714\n",
      "====> Epoch: 15 Average loss: 104.8573\n",
      "====> Test set loss: 104.4362\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 102.827385\n",
      "Train Epoch: 16 [1280/60000 (2%)]\tLoss: 105.224785\n",
      "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 106.098007\n",
      "Train Epoch: 16 [3840/60000 (6%)]\tLoss: 103.477127\n",
      "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 102.832916\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 104.122414\n",
      "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 110.333069\n",
      "Train Epoch: 16 [8960/60000 (15%)]\tLoss: 102.649323\n",
      "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 106.960602\n",
      "Train Epoch: 16 [11520/60000 (19%)]\tLoss: 106.991089\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 109.197739\n",
      "Train Epoch: 16 [14080/60000 (23%)]\tLoss: 105.203056\n",
      "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 105.740753\n",
      "Train Epoch: 16 [16640/60000 (28%)]\tLoss: 104.184708\n",
      "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 104.709457\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 106.090622\n",
      "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 103.242645\n",
      "Train Epoch: 16 [21760/60000 (36%)]\tLoss: 102.122253\n",
      "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 102.153107\n",
      "Train Epoch: 16 [24320/60000 (41%)]\tLoss: 101.580841\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 107.343002\n",
      "Train Epoch: 16 [26880/60000 (45%)]\tLoss: 102.473312\n",
      "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 103.601242\n",
      "Train Epoch: 16 [29440/60000 (49%)]\tLoss: 106.052063\n",
      "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 105.188400\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 105.240356\n",
      "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 105.788361\n",
      "Train Epoch: 16 [34560/60000 (58%)]\tLoss: 103.142235\n",
      "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 105.851280\n",
      "Train Epoch: 16 [37120/60000 (62%)]\tLoss: 105.018387\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 104.699532\n",
      "Train Epoch: 16 [39680/60000 (66%)]\tLoss: 102.774597\n",
      "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 101.755791\n",
      "Train Epoch: 16 [42240/60000 (70%)]\tLoss: 104.608330\n",
      "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 103.663879\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 103.388794\n",
      "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 102.697205\n",
      "Train Epoch: 16 [47360/60000 (79%)]\tLoss: 106.060951\n",
      "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 105.585976\n",
      "Train Epoch: 16 [49920/60000 (83%)]\tLoss: 106.113449\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 101.053436\n",
      "Train Epoch: 16 [52480/60000 (87%)]\tLoss: 101.653908\n",
      "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 101.653763\n",
      "Train Epoch: 16 [55040/60000 (92%)]\tLoss: 105.756203\n",
      "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 108.749619\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 102.418976\n",
      "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 104.634552\n",
      "====> Epoch: 16 Average loss: 104.6771\n",
      "====> Test set loss: 104.3226\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 104.639076\n",
      "Train Epoch: 17 [1280/60000 (2%)]\tLoss: 101.896454\n",
      "Train Epoch: 17 [2560/60000 (4%)]\tLoss: 104.665634\n",
      "Train Epoch: 17 [3840/60000 (6%)]\tLoss: 107.521637\n",
      "Train Epoch: 17 [5120/60000 (9%)]\tLoss: 102.559555\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 102.302109\n",
      "Train Epoch: 17 [7680/60000 (13%)]\tLoss: 101.477203\n",
      "Train Epoch: 17 [8960/60000 (15%)]\tLoss: 102.382935\n",
      "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 105.766884\n",
      "Train Epoch: 17 [11520/60000 (19%)]\tLoss: 99.764168\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 101.700760\n",
      "Train Epoch: 17 [14080/60000 (23%)]\tLoss: 106.974777\n",
      "Train Epoch: 17 [15360/60000 (26%)]\tLoss: 103.769485\n",
      "Train Epoch: 17 [16640/60000 (28%)]\tLoss: 106.335892\n",
      "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 102.692749\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 104.604210\n",
      "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 103.757416\n",
      "Train Epoch: 17 [21760/60000 (36%)]\tLoss: 105.763794\n",
      "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 103.290329\n",
      "Train Epoch: 17 [24320/60000 (41%)]\tLoss: 105.963478\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 103.332413\n",
      "Train Epoch: 17 [26880/60000 (45%)]\tLoss: 106.418213\n",
      "Train Epoch: 17 [28160/60000 (47%)]\tLoss: 103.322113\n",
      "Train Epoch: 17 [29440/60000 (49%)]\tLoss: 108.534676\n",
      "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 104.717033\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 104.928131\n",
      "Train Epoch: 17 [33280/60000 (55%)]\tLoss: 108.173050\n",
      "Train Epoch: 17 [34560/60000 (58%)]\tLoss: 103.889481\n",
      "Train Epoch: 17 [35840/60000 (60%)]\tLoss: 102.056259\n",
      "Train Epoch: 17 [37120/60000 (62%)]\tLoss: 107.566429\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 103.514374\n",
      "Train Epoch: 17 [39680/60000 (66%)]\tLoss: 99.313332\n",
      "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 105.651718\n",
      "Train Epoch: 17 [42240/60000 (70%)]\tLoss: 107.734070\n",
      "Train Epoch: 17 [43520/60000 (72%)]\tLoss: 99.906067\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 103.306953\n",
      "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 106.084167\n",
      "Train Epoch: 17 [47360/60000 (79%)]\tLoss: 105.799271\n",
      "Train Epoch: 17 [48640/60000 (81%)]\tLoss: 105.455696\n",
      "Train Epoch: 17 [49920/60000 (83%)]\tLoss: 102.610924\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 103.184509\n",
      "Train Epoch: 17 [52480/60000 (87%)]\tLoss: 102.767113\n",
      "Train Epoch: 17 [53760/60000 (90%)]\tLoss: 106.146263\n",
      "Train Epoch: 17 [55040/60000 (92%)]\tLoss: 105.019485\n",
      "Train Epoch: 17 [56320/60000 (94%)]\tLoss: 108.904816\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 104.024231\n",
      "Train Epoch: 17 [58880/60000 (98%)]\tLoss: 104.146637\n",
      "====> Epoch: 17 Average loss: 104.4469\n",
      "====> Test set loss: 104.1010\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 106.182236\n",
      "Train Epoch: 18 [1280/60000 (2%)]\tLoss: 108.390945\n",
      "Train Epoch: 18 [2560/60000 (4%)]\tLoss: 104.247482\n",
      "Train Epoch: 18 [3840/60000 (6%)]\tLoss: 104.482513\n",
      "Train Epoch: 18 [5120/60000 (9%)]\tLoss: 105.276367\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 102.544350\n",
      "Train Epoch: 18 [7680/60000 (13%)]\tLoss: 102.711182\n",
      "Train Epoch: 18 [8960/60000 (15%)]\tLoss: 101.708206\n",
      "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 102.402313\n",
      "Train Epoch: 18 [11520/60000 (19%)]\tLoss: 100.807915\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 105.207367\n",
      "Train Epoch: 18 [14080/60000 (23%)]\tLoss: 105.936607\n",
      "Train Epoch: 18 [15360/60000 (26%)]\tLoss: 103.528625\n",
      "Train Epoch: 18 [16640/60000 (28%)]\tLoss: 102.461052\n",
      "Train Epoch: 18 [17920/60000 (30%)]\tLoss: 106.112259\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 102.478554\n",
      "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 105.798004\n",
      "Train Epoch: 18 [21760/60000 (36%)]\tLoss: 105.403534\n",
      "Train Epoch: 18 [23040/60000 (38%)]\tLoss: 108.881607\n",
      "Train Epoch: 18 [24320/60000 (41%)]\tLoss: 106.252235\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 102.311905\n",
      "Train Epoch: 18 [26880/60000 (45%)]\tLoss: 107.683441\n",
      "Train Epoch: 18 [28160/60000 (47%)]\tLoss: 105.647995\n",
      "Train Epoch: 18 [29440/60000 (49%)]\tLoss: 103.151688\n",
      "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 103.120934\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 104.704208\n",
      "Train Epoch: 18 [33280/60000 (55%)]\tLoss: 103.038750\n",
      "Train Epoch: 18 [34560/60000 (58%)]\tLoss: 105.503571\n",
      "Train Epoch: 18 [35840/60000 (60%)]\tLoss: 106.626556\n",
      "Train Epoch: 18 [37120/60000 (62%)]\tLoss: 104.075684\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 99.269310\n",
      "Train Epoch: 18 [39680/60000 (66%)]\tLoss: 104.585365\n",
      "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 100.252991\n",
      "Train Epoch: 18 [42240/60000 (70%)]\tLoss: 106.332222\n",
      "Train Epoch: 18 [43520/60000 (72%)]\tLoss: 102.621521\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 105.792450\n",
      "Train Epoch: 18 [46080/60000 (77%)]\tLoss: 106.520432\n",
      "Train Epoch: 18 [47360/60000 (79%)]\tLoss: 105.967278\n",
      "Train Epoch: 18 [48640/60000 (81%)]\tLoss: 97.064064\n",
      "Train Epoch: 18 [49920/60000 (83%)]\tLoss: 102.945320\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 103.813576\n",
      "Train Epoch: 18 [52480/60000 (87%)]\tLoss: 104.303253\n",
      "Train Epoch: 18 [53760/60000 (90%)]\tLoss: 107.056465\n",
      "Train Epoch: 18 [55040/60000 (92%)]\tLoss: 102.258774\n",
      "Train Epoch: 18 [56320/60000 (94%)]\tLoss: 106.526169\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 102.836731\n",
      "Train Epoch: 18 [58880/60000 (98%)]\tLoss: 107.397873\n",
      "====> Epoch: 18 Average loss: 104.3161\n",
      "====> Test set loss: 104.0982\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 102.173836\n",
      "Train Epoch: 19 [1280/60000 (2%)]\tLoss: 104.206306\n",
      "Train Epoch: 19 [2560/60000 (4%)]\tLoss: 104.159462\n",
      "Train Epoch: 19 [3840/60000 (6%)]\tLoss: 104.608139\n",
      "Train Epoch: 19 [5120/60000 (9%)]\tLoss: 101.483643\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 106.238907\n",
      "Train Epoch: 19 [7680/60000 (13%)]\tLoss: 104.036880\n",
      "Train Epoch: 19 [8960/60000 (15%)]\tLoss: 108.256157\n",
      "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 104.776688\n",
      "Train Epoch: 19 [11520/60000 (19%)]\tLoss: 106.277519\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 101.135597\n",
      "Train Epoch: 19 [14080/60000 (23%)]\tLoss: 102.407455\n",
      "Train Epoch: 19 [15360/60000 (26%)]\tLoss: 103.654831\n",
      "Train Epoch: 19 [16640/60000 (28%)]\tLoss: 102.859016\n",
      "Train Epoch: 19 [17920/60000 (30%)]\tLoss: 103.925613\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 100.781441\n",
      "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 104.796211\n",
      "Train Epoch: 19 [21760/60000 (36%)]\tLoss: 102.830338\n",
      "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 102.567749\n",
      "Train Epoch: 19 [24320/60000 (41%)]\tLoss: 101.153885\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 103.130417\n",
      "Train Epoch: 19 [26880/60000 (45%)]\tLoss: 109.026588\n",
      "Train Epoch: 19 [28160/60000 (47%)]\tLoss: 100.236809\n",
      "Train Epoch: 19 [29440/60000 (49%)]\tLoss: 105.372559\n",
      "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 105.219299\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 106.607140\n",
      "Train Epoch: 19 [33280/60000 (55%)]\tLoss: 102.332001\n",
      "Train Epoch: 19 [34560/60000 (58%)]\tLoss: 103.697586\n",
      "Train Epoch: 19 [35840/60000 (60%)]\tLoss: 107.299683\n",
      "Train Epoch: 19 [37120/60000 (62%)]\tLoss: 103.857231\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 103.345352\n",
      "Train Epoch: 19 [39680/60000 (66%)]\tLoss: 103.850067\n",
      "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 106.437210\n",
      "Train Epoch: 19 [42240/60000 (70%)]\tLoss: 107.942413\n",
      "Train Epoch: 19 [43520/60000 (72%)]\tLoss: 108.478012\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 108.557419\n",
      "Train Epoch: 19 [46080/60000 (77%)]\tLoss: 104.001419\n",
      "Train Epoch: 19 [47360/60000 (79%)]\tLoss: 103.823517\n",
      "Train Epoch: 19 [48640/60000 (81%)]\tLoss: 101.990631\n",
      "Train Epoch: 19 [49920/60000 (83%)]\tLoss: 100.962296\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 104.271774\n",
      "Train Epoch: 19 [52480/60000 (87%)]\tLoss: 104.616516\n",
      "Train Epoch: 19 [53760/60000 (90%)]\tLoss: 105.068695\n",
      "Train Epoch: 19 [55040/60000 (92%)]\tLoss: 104.733406\n",
      "Train Epoch: 19 [56320/60000 (94%)]\tLoss: 106.232376\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 103.940979\n",
      "Train Epoch: 19 [58880/60000 (98%)]\tLoss: 102.827438\n",
      "====> Epoch: 19 Average loss: 104.1719\n",
      "====> Test set loss: 104.0011\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 100.689941\n",
      "Train Epoch: 20 [1280/60000 (2%)]\tLoss: 108.469383\n",
      "Train Epoch: 20 [2560/60000 (4%)]\tLoss: 105.555145\n",
      "Train Epoch: 20 [3840/60000 (6%)]\tLoss: 103.125320\n",
      "Train Epoch: 20 [5120/60000 (9%)]\tLoss: 104.792221\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 105.584831\n",
      "Train Epoch: 20 [7680/60000 (13%)]\tLoss: 100.333969\n",
      "Train Epoch: 20 [8960/60000 (15%)]\tLoss: 98.855515\n",
      "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 98.939484\n",
      "Train Epoch: 20 [11520/60000 (19%)]\tLoss: 104.401489\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 101.360062\n",
      "Train Epoch: 20 [14080/60000 (23%)]\tLoss: 102.118210\n",
      "Train Epoch: 20 [15360/60000 (26%)]\tLoss: 105.998100\n",
      "Train Epoch: 20 [16640/60000 (28%)]\tLoss: 105.055176\n",
      "Train Epoch: 20 [17920/60000 (30%)]\tLoss: 106.230156\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 106.068146\n",
      "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 102.557755\n",
      "Train Epoch: 20 [21760/60000 (36%)]\tLoss: 104.133804\n",
      "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 106.645531\n",
      "Train Epoch: 20 [24320/60000 (41%)]\tLoss: 104.239792\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 103.331032\n",
      "Train Epoch: 20 [26880/60000 (45%)]\tLoss: 104.658241\n",
      "Train Epoch: 20 [28160/60000 (47%)]\tLoss: 105.578568\n",
      "Train Epoch: 20 [29440/60000 (49%)]\tLoss: 103.388405\n",
      "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 109.469574\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 107.827217\n",
      "Train Epoch: 20 [33280/60000 (55%)]\tLoss: 101.224808\n",
      "Train Epoch: 20 [34560/60000 (58%)]\tLoss: 105.199486\n",
      "Train Epoch: 20 [35840/60000 (60%)]\tLoss: 107.320343\n",
      "Train Epoch: 20 [37120/60000 (62%)]\tLoss: 101.863205\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 104.167610\n",
      "Train Epoch: 20 [39680/60000 (66%)]\tLoss: 99.991379\n",
      "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 107.866119\n",
      "Train Epoch: 20 [42240/60000 (70%)]\tLoss: 100.580582\n",
      "Train Epoch: 20 [43520/60000 (72%)]\tLoss: 105.996704\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 108.259613\n",
      "Train Epoch: 20 [46080/60000 (77%)]\tLoss: 104.011902\n",
      "Train Epoch: 20 [47360/60000 (79%)]\tLoss: 98.428093\n",
      "Train Epoch: 20 [48640/60000 (81%)]\tLoss: 102.340050\n",
      "Train Epoch: 20 [49920/60000 (83%)]\tLoss: 102.668732\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 102.185486\n",
      "Train Epoch: 20 [52480/60000 (87%)]\tLoss: 103.706131\n",
      "Train Epoch: 20 [53760/60000 (90%)]\tLoss: 107.092529\n",
      "Train Epoch: 20 [55040/60000 (92%)]\tLoss: 102.926514\n",
      "Train Epoch: 20 [56320/60000 (94%)]\tLoss: 103.398582\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 104.998306\n",
      "Train Epoch: 20 [58880/60000 (98%)]\tLoss: 102.404907\n",
      "====> Epoch: 20 Average loss: 104.0049\n",
      "====> Test set loss: 103.8940\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 103.539322\n",
      "Train Epoch: 21 [1280/60000 (2%)]\tLoss: 104.241425\n",
      "Train Epoch: 21 [2560/60000 (4%)]\tLoss: 103.677124\n",
      "Train Epoch: 21 [3840/60000 (6%)]\tLoss: 105.167801\n",
      "Train Epoch: 21 [5120/60000 (9%)]\tLoss: 106.856911\n",
      "Train Epoch: 21 [6400/60000 (11%)]\tLoss: 103.769279\n",
      "Train Epoch: 21 [7680/60000 (13%)]\tLoss: 103.696251\n",
      "Train Epoch: 21 [8960/60000 (15%)]\tLoss: 101.176064\n",
      "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 102.971512\n",
      "Train Epoch: 21 [11520/60000 (19%)]\tLoss: 102.495239\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 98.437271\n",
      "Train Epoch: 21 [14080/60000 (23%)]\tLoss: 103.179565\n",
      "Train Epoch: 21 [15360/60000 (26%)]\tLoss: 106.350777\n",
      "Train Epoch: 21 [16640/60000 (28%)]\tLoss: 104.024361\n",
      "Train Epoch: 21 [17920/60000 (30%)]\tLoss: 105.577278\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 105.355598\n",
      "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 101.659782\n",
      "Train Epoch: 21 [21760/60000 (36%)]\tLoss: 106.090851\n",
      "Train Epoch: 21 [23040/60000 (38%)]\tLoss: 100.137428\n",
      "Train Epoch: 21 [24320/60000 (41%)]\tLoss: 104.539604\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 101.250351\n",
      "Train Epoch: 21 [26880/60000 (45%)]\tLoss: 104.236053\n",
      "Train Epoch: 21 [28160/60000 (47%)]\tLoss: 105.270958\n",
      "Train Epoch: 21 [29440/60000 (49%)]\tLoss: 98.508286\n",
      "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 104.485275\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 104.996758\n",
      "Train Epoch: 21 [33280/60000 (55%)]\tLoss: 109.328651\n",
      "Train Epoch: 21 [34560/60000 (58%)]\tLoss: 103.471924\n",
      "Train Epoch: 21 [35840/60000 (60%)]\tLoss: 106.648354\n",
      "Train Epoch: 21 [37120/60000 (62%)]\tLoss: 103.169586\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 103.385223\n",
      "Train Epoch: 21 [39680/60000 (66%)]\tLoss: 107.699875\n",
      "Train Epoch: 21 [40960/60000 (68%)]\tLoss: 101.873505\n",
      "Train Epoch: 21 [42240/60000 (70%)]\tLoss: 105.207306\n",
      "Train Epoch: 21 [43520/60000 (72%)]\tLoss: 104.871536\n",
      "Train Epoch: 21 [44800/60000 (75%)]\tLoss: 104.167557\n",
      "Train Epoch: 21 [46080/60000 (77%)]\tLoss: 102.057320\n",
      "Train Epoch: 21 [47360/60000 (79%)]\tLoss: 103.960678\n",
      "Train Epoch: 21 [48640/60000 (81%)]\tLoss: 105.066864\n",
      "Train Epoch: 21 [49920/60000 (83%)]\tLoss: 104.455933\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 103.913963\n",
      "Train Epoch: 21 [52480/60000 (87%)]\tLoss: 105.412773\n",
      "Train Epoch: 21 [53760/60000 (90%)]\tLoss: 102.818222\n",
      "Train Epoch: 21 [55040/60000 (92%)]\tLoss: 101.537216\n",
      "Train Epoch: 21 [56320/60000 (94%)]\tLoss: 100.928230\n",
      "Train Epoch: 21 [57600/60000 (96%)]\tLoss: 104.982658\n",
      "Train Epoch: 21 [58880/60000 (98%)]\tLoss: 103.964981\n",
      "====> Epoch: 21 Average loss: 103.8675\n",
      "====> Test set loss: 103.8326\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 103.928146\n",
      "Train Epoch: 22 [1280/60000 (2%)]\tLoss: 104.028046\n",
      "Train Epoch: 22 [2560/60000 (4%)]\tLoss: 101.520554\n",
      "Train Epoch: 22 [3840/60000 (6%)]\tLoss: 102.035118\n",
      "Train Epoch: 22 [5120/60000 (9%)]\tLoss: 106.058617\n",
      "Train Epoch: 22 [6400/60000 (11%)]\tLoss: 103.229965\n",
      "Train Epoch: 22 [7680/60000 (13%)]\tLoss: 105.371841\n",
      "Train Epoch: 22 [8960/60000 (15%)]\tLoss: 103.078407\n",
      "Train Epoch: 22 [10240/60000 (17%)]\tLoss: 105.326691\n",
      "Train Epoch: 22 [11520/60000 (19%)]\tLoss: 106.660202\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 101.948410\n",
      "Train Epoch: 22 [14080/60000 (23%)]\tLoss: 102.714149\n",
      "Train Epoch: 22 [15360/60000 (26%)]\tLoss: 107.048553\n",
      "Train Epoch: 22 [16640/60000 (28%)]\tLoss: 102.913673\n",
      "Train Epoch: 22 [17920/60000 (30%)]\tLoss: 104.916641\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 104.905594\n",
      "Train Epoch: 22 [20480/60000 (34%)]\tLoss: 102.802010\n",
      "Train Epoch: 22 [21760/60000 (36%)]\tLoss: 104.005356\n",
      "Train Epoch: 22 [23040/60000 (38%)]\tLoss: 106.179764\n",
      "Train Epoch: 22 [24320/60000 (41%)]\tLoss: 107.777359\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 100.873917\n",
      "Train Epoch: 22 [26880/60000 (45%)]\tLoss: 104.042526\n",
      "Train Epoch: 22 [28160/60000 (47%)]\tLoss: 102.509048\n",
      "Train Epoch: 22 [29440/60000 (49%)]\tLoss: 99.770805\n",
      "Train Epoch: 22 [30720/60000 (51%)]\tLoss: 104.118927\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 102.150368\n",
      "Train Epoch: 22 [33280/60000 (55%)]\tLoss: 107.395340\n",
      "Train Epoch: 22 [34560/60000 (58%)]\tLoss: 104.008728\n",
      "Train Epoch: 22 [35840/60000 (60%)]\tLoss: 103.008545\n",
      "Train Epoch: 22 [37120/60000 (62%)]\tLoss: 101.511986\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 102.213524\n",
      "Train Epoch: 22 [39680/60000 (66%)]\tLoss: 105.941315\n",
      "Train Epoch: 22 [40960/60000 (68%)]\tLoss: 103.725250\n",
      "Train Epoch: 22 [42240/60000 (70%)]\tLoss: 106.654343\n",
      "Train Epoch: 22 [43520/60000 (72%)]\tLoss: 103.377380\n",
      "Train Epoch: 22 [44800/60000 (75%)]\tLoss: 108.728508\n",
      "Train Epoch: 22 [46080/60000 (77%)]\tLoss: 100.689026\n",
      "Train Epoch: 22 [47360/60000 (79%)]\tLoss: 105.114960\n",
      "Train Epoch: 22 [48640/60000 (81%)]\tLoss: 103.048630\n",
      "Train Epoch: 22 [49920/60000 (83%)]\tLoss: 104.260963\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 104.501877\n",
      "Train Epoch: 22 [52480/60000 (87%)]\tLoss: 96.946953\n",
      "Train Epoch: 22 [53760/60000 (90%)]\tLoss: 104.763954\n",
      "Train Epoch: 22 [55040/60000 (92%)]\tLoss: 107.287056\n",
      "Train Epoch: 22 [56320/60000 (94%)]\tLoss: 105.546021\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 102.821465\n",
      "Train Epoch: 22 [58880/60000 (98%)]\tLoss: 102.787979\n",
      "====> Epoch: 22 Average loss: 103.7423\n",
      "====> Test set loss: 103.5150\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 104.229874\n",
      "Train Epoch: 23 [1280/60000 (2%)]\tLoss: 103.759995\n",
      "Train Epoch: 23 [2560/60000 (4%)]\tLoss: 100.317642\n",
      "Train Epoch: 23 [3840/60000 (6%)]\tLoss: 98.138954\n",
      "Train Epoch: 23 [5120/60000 (9%)]\tLoss: 104.444199\n",
      "Train Epoch: 23 [6400/60000 (11%)]\tLoss: 104.241730\n",
      "Train Epoch: 23 [7680/60000 (13%)]\tLoss: 105.403412\n",
      "Train Epoch: 23 [8960/60000 (15%)]\tLoss: 104.779251\n",
      "Train Epoch: 23 [10240/60000 (17%)]\tLoss: 105.042007\n",
      "Train Epoch: 23 [11520/60000 (19%)]\tLoss: 101.895729\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 104.804306\n",
      "Train Epoch: 23 [14080/60000 (23%)]\tLoss: 103.556419\n",
      "Train Epoch: 23 [15360/60000 (26%)]\tLoss: 103.594482\n",
      "Train Epoch: 23 [16640/60000 (28%)]\tLoss: 102.348557\n",
      "Train Epoch: 23 [17920/60000 (30%)]\tLoss: 104.657532\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 105.279190\n",
      "Train Epoch: 23 [20480/60000 (34%)]\tLoss: 106.090500\n",
      "Train Epoch: 23 [21760/60000 (36%)]\tLoss: 101.701378\n",
      "Train Epoch: 23 [23040/60000 (38%)]\tLoss: 102.192932\n",
      "Train Epoch: 23 [24320/60000 (41%)]\tLoss: 99.843933\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 110.750366\n",
      "Train Epoch: 23 [26880/60000 (45%)]\tLoss: 104.186394\n",
      "Train Epoch: 23 [28160/60000 (47%)]\tLoss: 101.806961\n",
      "Train Epoch: 23 [29440/60000 (49%)]\tLoss: 104.028900\n",
      "Train Epoch: 23 [30720/60000 (51%)]\tLoss: 101.090286\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 103.797699\n",
      "Train Epoch: 23 [33280/60000 (55%)]\tLoss: 102.690735\n",
      "Train Epoch: 23 [34560/60000 (58%)]\tLoss: 105.879906\n",
      "Train Epoch: 23 [35840/60000 (60%)]\tLoss: 104.140427\n",
      "Train Epoch: 23 [37120/60000 (62%)]\tLoss: 104.539902\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 104.257805\n",
      "Train Epoch: 23 [39680/60000 (66%)]\tLoss: 103.152016\n",
      "Train Epoch: 23 [40960/60000 (68%)]\tLoss: 104.026344\n",
      "Train Epoch: 23 [42240/60000 (70%)]\tLoss: 102.374527\n",
      "Train Epoch: 23 [43520/60000 (72%)]\tLoss: 101.824783\n",
      "Train Epoch: 23 [44800/60000 (75%)]\tLoss: 107.812698\n",
      "Train Epoch: 23 [46080/60000 (77%)]\tLoss: 101.118935\n",
      "Train Epoch: 23 [47360/60000 (79%)]\tLoss: 103.724640\n",
      "Train Epoch: 23 [48640/60000 (81%)]\tLoss: 102.729134\n",
      "Train Epoch: 23 [49920/60000 (83%)]\tLoss: 102.288803\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 102.226746\n",
      "Train Epoch: 23 [52480/60000 (87%)]\tLoss: 106.881393\n",
      "Train Epoch: 23 [53760/60000 (90%)]\tLoss: 104.830612\n",
      "Train Epoch: 23 [55040/60000 (92%)]\tLoss: 106.205933\n",
      "Train Epoch: 23 [56320/60000 (94%)]\tLoss: 104.936340\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 101.907730\n",
      "Train Epoch: 23 [58880/60000 (98%)]\tLoss: 103.170059\n",
      "====> Epoch: 23 Average loss: 103.6109\n",
      "====> Test set loss: 103.6642\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 108.053757\n",
      "Train Epoch: 24 [1280/60000 (2%)]\tLoss: 103.385529\n",
      "Train Epoch: 24 [2560/60000 (4%)]\tLoss: 104.221519\n",
      "Train Epoch: 24 [3840/60000 (6%)]\tLoss: 101.985634\n",
      "Train Epoch: 24 [5120/60000 (9%)]\tLoss: 101.440552\n",
      "Train Epoch: 24 [6400/60000 (11%)]\tLoss: 101.681984\n",
      "Train Epoch: 24 [7680/60000 (13%)]\tLoss: 105.305389\n",
      "Train Epoch: 24 [8960/60000 (15%)]\tLoss: 105.418594\n",
      "Train Epoch: 24 [10240/60000 (17%)]\tLoss: 104.125504\n",
      "Train Epoch: 24 [11520/60000 (19%)]\tLoss: 102.241852\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 107.183601\n",
      "Train Epoch: 24 [14080/60000 (23%)]\tLoss: 104.089005\n",
      "Train Epoch: 24 [15360/60000 (26%)]\tLoss: 105.171715\n",
      "Train Epoch: 24 [16640/60000 (28%)]\tLoss: 105.527756\n",
      "Train Epoch: 24 [17920/60000 (30%)]\tLoss: 104.007828\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 101.582932\n",
      "Train Epoch: 24 [20480/60000 (34%)]\tLoss: 105.981369\n",
      "Train Epoch: 24 [21760/60000 (36%)]\tLoss: 101.422813\n",
      "Train Epoch: 24 [23040/60000 (38%)]\tLoss: 103.081909\n",
      "Train Epoch: 24 [24320/60000 (41%)]\tLoss: 105.597580\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 100.451103\n",
      "Train Epoch: 24 [26880/60000 (45%)]\tLoss: 102.078690\n",
      "Train Epoch: 24 [28160/60000 (47%)]\tLoss: 101.152969\n",
      "Train Epoch: 24 [29440/60000 (49%)]\tLoss: 104.306847\n",
      "Train Epoch: 24 [30720/60000 (51%)]\tLoss: 103.513184\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 102.992073\n",
      "Train Epoch: 24 [33280/60000 (55%)]\tLoss: 103.045914\n",
      "Train Epoch: 24 [34560/60000 (58%)]\tLoss: 103.599281\n",
      "Train Epoch: 24 [35840/60000 (60%)]\tLoss: 101.514984\n",
      "Train Epoch: 24 [37120/60000 (62%)]\tLoss: 98.552353\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 101.588013\n",
      "Train Epoch: 24 [39680/60000 (66%)]\tLoss: 108.518478\n",
      "Train Epoch: 24 [40960/60000 (68%)]\tLoss: 102.414825\n",
      "Train Epoch: 24 [42240/60000 (70%)]\tLoss: 99.588913\n",
      "Train Epoch: 24 [43520/60000 (72%)]\tLoss: 108.467010\n",
      "Train Epoch: 24 [44800/60000 (75%)]\tLoss: 100.812798\n",
      "Train Epoch: 24 [46080/60000 (77%)]\tLoss: 100.312912\n",
      "Train Epoch: 24 [47360/60000 (79%)]\tLoss: 101.148026\n",
      "Train Epoch: 24 [48640/60000 (81%)]\tLoss: 101.129372\n",
      "Train Epoch: 24 [49920/60000 (83%)]\tLoss: 103.637611\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 102.806190\n",
      "Train Epoch: 24 [52480/60000 (87%)]\tLoss: 106.006485\n",
      "Train Epoch: 24 [53760/60000 (90%)]\tLoss: 101.413734\n",
      "Train Epoch: 24 [55040/60000 (92%)]\tLoss: 102.792610\n",
      "Train Epoch: 24 [56320/60000 (94%)]\tLoss: 104.060020\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 97.361084\n",
      "Train Epoch: 24 [58880/60000 (98%)]\tLoss: 102.392334\n",
      "====> Epoch: 24 Average loss: 103.4675\n",
      "====> Test set loss: 103.4669\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 102.350830\n",
      "Train Epoch: 25 [1280/60000 (2%)]\tLoss: 105.082695\n",
      "Train Epoch: 25 [2560/60000 (4%)]\tLoss: 105.982971\n",
      "Train Epoch: 25 [3840/60000 (6%)]\tLoss: 104.998795\n",
      "Train Epoch: 25 [5120/60000 (9%)]\tLoss: 103.607536\n",
      "Train Epoch: 25 [6400/60000 (11%)]\tLoss: 102.964287\n",
      "Train Epoch: 25 [7680/60000 (13%)]\tLoss: 104.838516\n",
      "Train Epoch: 25 [8960/60000 (15%)]\tLoss: 107.155502\n",
      "Train Epoch: 25 [10240/60000 (17%)]\tLoss: 103.222107\n",
      "Train Epoch: 25 [11520/60000 (19%)]\tLoss: 106.490395\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 106.765167\n",
      "Train Epoch: 25 [14080/60000 (23%)]\tLoss: 105.968338\n",
      "Train Epoch: 25 [15360/60000 (26%)]\tLoss: 103.384827\n",
      "Train Epoch: 25 [16640/60000 (28%)]\tLoss: 103.915344\n",
      "Train Epoch: 25 [17920/60000 (30%)]\tLoss: 103.108658\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 102.283951\n",
      "Train Epoch: 25 [20480/60000 (34%)]\tLoss: 105.269127\n",
      "Train Epoch: 25 [21760/60000 (36%)]\tLoss: 106.881790\n",
      "Train Epoch: 25 [23040/60000 (38%)]\tLoss: 105.683899\n",
      "Train Epoch: 25 [24320/60000 (41%)]\tLoss: 104.105972\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 109.955544\n",
      "Train Epoch: 25 [26880/60000 (45%)]\tLoss: 103.632973\n",
      "Train Epoch: 25 [28160/60000 (47%)]\tLoss: 104.022919\n",
      "Train Epoch: 25 [29440/60000 (49%)]\tLoss: 106.342361\n",
      "Train Epoch: 25 [30720/60000 (51%)]\tLoss: 99.380005\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 100.953194\n",
      "Train Epoch: 25 [33280/60000 (55%)]\tLoss: 103.478165\n",
      "Train Epoch: 25 [34560/60000 (58%)]\tLoss: 106.018700\n",
      "Train Epoch: 25 [35840/60000 (60%)]\tLoss: 102.415771\n",
      "Train Epoch: 25 [37120/60000 (62%)]\tLoss: 102.640892\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 105.605606\n",
      "Train Epoch: 25 [39680/60000 (66%)]\tLoss: 103.952148\n",
      "Train Epoch: 25 [40960/60000 (68%)]\tLoss: 103.040703\n",
      "Train Epoch: 25 [42240/60000 (70%)]\tLoss: 104.412880\n",
      "Train Epoch: 25 [43520/60000 (72%)]\tLoss: 105.673965\n",
      "Train Epoch: 25 [44800/60000 (75%)]\tLoss: 104.783173\n",
      "Train Epoch: 25 [46080/60000 (77%)]\tLoss: 103.922729\n",
      "Train Epoch: 25 [47360/60000 (79%)]\tLoss: 103.358002\n",
      "Train Epoch: 25 [48640/60000 (81%)]\tLoss: 100.900848\n",
      "Train Epoch: 25 [49920/60000 (83%)]\tLoss: 106.802017\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 102.215027\n",
      "Train Epoch: 25 [52480/60000 (87%)]\tLoss: 106.183578\n",
      "Train Epoch: 25 [53760/60000 (90%)]\tLoss: 102.436928\n",
      "Train Epoch: 25 [55040/60000 (92%)]\tLoss: 105.551285\n",
      "Train Epoch: 25 [56320/60000 (94%)]\tLoss: 105.833916\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 102.831619\n",
      "Train Epoch: 25 [58880/60000 (98%)]\tLoss: 102.976982\n",
      "====> Epoch: 25 Average loss: 103.3791\n",
      "====> Test set loss: 103.4943\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 105.021484\n",
      "Train Epoch: 26 [1280/60000 (2%)]\tLoss: 106.257080\n",
      "Train Epoch: 26 [2560/60000 (4%)]\tLoss: 106.148911\n",
      "Train Epoch: 26 [3840/60000 (6%)]\tLoss: 104.152863\n",
      "Train Epoch: 26 [5120/60000 (9%)]\tLoss: 106.982483\n",
      "Train Epoch: 26 [6400/60000 (11%)]\tLoss: 102.316277\n",
      "Train Epoch: 26 [7680/60000 (13%)]\tLoss: 97.638496\n",
      "Train Epoch: 26 [8960/60000 (15%)]\tLoss: 106.548660\n",
      "Train Epoch: 26 [10240/60000 (17%)]\tLoss: 99.483643\n",
      "Train Epoch: 26 [11520/60000 (19%)]\tLoss: 101.947586\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 101.285263\n",
      "Train Epoch: 26 [14080/60000 (23%)]\tLoss: 105.400810\n",
      "Train Epoch: 26 [15360/60000 (26%)]\tLoss: 102.404083\n",
      "Train Epoch: 26 [16640/60000 (28%)]\tLoss: 101.267624\n",
      "Train Epoch: 26 [17920/60000 (30%)]\tLoss: 103.487366\n",
      "Train Epoch: 26 [19200/60000 (32%)]\tLoss: 102.234840\n",
      "Train Epoch: 26 [20480/60000 (34%)]\tLoss: 105.612839\n",
      "Train Epoch: 26 [21760/60000 (36%)]\tLoss: 106.659164\n",
      "Train Epoch: 26 [23040/60000 (38%)]\tLoss: 100.946198\n",
      "Train Epoch: 26 [24320/60000 (41%)]\tLoss: 97.745728\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 104.075356\n",
      "Train Epoch: 26 [26880/60000 (45%)]\tLoss: 100.399750\n",
      "Train Epoch: 26 [28160/60000 (47%)]\tLoss: 104.901566\n",
      "Train Epoch: 26 [29440/60000 (49%)]\tLoss: 103.126511\n",
      "Train Epoch: 26 [30720/60000 (51%)]\tLoss: 102.051010\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 103.811501\n",
      "Train Epoch: 26 [33280/60000 (55%)]\tLoss: 101.658760\n",
      "Train Epoch: 26 [34560/60000 (58%)]\tLoss: 98.613968\n",
      "Train Epoch: 26 [35840/60000 (60%)]\tLoss: 100.438812\n",
      "Train Epoch: 26 [37120/60000 (62%)]\tLoss: 104.189171\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 103.395966\n",
      "Train Epoch: 26 [39680/60000 (66%)]\tLoss: 101.625336\n",
      "Train Epoch: 26 [40960/60000 (68%)]\tLoss: 99.303612\n",
      "Train Epoch: 26 [42240/60000 (70%)]\tLoss: 99.906601\n",
      "Train Epoch: 26 [43520/60000 (72%)]\tLoss: 104.074806\n",
      "Train Epoch: 26 [44800/60000 (75%)]\tLoss: 103.672714\n",
      "Train Epoch: 26 [46080/60000 (77%)]\tLoss: 101.875244\n",
      "Train Epoch: 26 [47360/60000 (79%)]\tLoss: 106.564316\n",
      "Train Epoch: 26 [48640/60000 (81%)]\tLoss: 105.895195\n",
      "Train Epoch: 26 [49920/60000 (83%)]\tLoss: 105.250946\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 104.716415\n",
      "Train Epoch: 26 [52480/60000 (87%)]\tLoss: 102.620117\n",
      "Train Epoch: 26 [53760/60000 (90%)]\tLoss: 99.848930\n",
      "Train Epoch: 26 [55040/60000 (92%)]\tLoss: 100.191833\n",
      "Train Epoch: 26 [56320/60000 (94%)]\tLoss: 105.995796\n",
      "Train Epoch: 26 [57600/60000 (96%)]\tLoss: 102.646255\n",
      "Train Epoch: 26 [58880/60000 (98%)]\tLoss: 105.016518\n",
      "====> Epoch: 26 Average loss: 103.2945\n",
      "====> Test set loss: 103.2654\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 105.374626\n",
      "Train Epoch: 27 [1280/60000 (2%)]\tLoss: 101.561172\n",
      "Train Epoch: 27 [2560/60000 (4%)]\tLoss: 103.928299\n",
      "Train Epoch: 27 [3840/60000 (6%)]\tLoss: 101.755295\n",
      "Train Epoch: 27 [5120/60000 (9%)]\tLoss: 100.664284\n",
      "Train Epoch: 27 [6400/60000 (11%)]\tLoss: 103.836914\n",
      "Train Epoch: 27 [7680/60000 (13%)]\tLoss: 102.935394\n",
      "Train Epoch: 27 [8960/60000 (15%)]\tLoss: 107.133484\n",
      "Train Epoch: 27 [10240/60000 (17%)]\tLoss: 102.529343\n",
      "Train Epoch: 27 [11520/60000 (19%)]\tLoss: 106.285385\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 104.430466\n",
      "Train Epoch: 27 [14080/60000 (23%)]\tLoss: 105.704681\n",
      "Train Epoch: 27 [15360/60000 (26%)]\tLoss: 99.352219\n",
      "Train Epoch: 27 [16640/60000 (28%)]\tLoss: 103.782578\n",
      "Train Epoch: 27 [17920/60000 (30%)]\tLoss: 103.429260\n",
      "Train Epoch: 27 [19200/60000 (32%)]\tLoss: 104.054298\n",
      "Train Epoch: 27 [20480/60000 (34%)]\tLoss: 103.252884\n",
      "Train Epoch: 27 [21760/60000 (36%)]\tLoss: 103.629944\n",
      "Train Epoch: 27 [23040/60000 (38%)]\tLoss: 104.940857\n",
      "Train Epoch: 27 [24320/60000 (41%)]\tLoss: 99.798721\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 104.657433\n",
      "Train Epoch: 27 [26880/60000 (45%)]\tLoss: 106.921303\n",
      "Train Epoch: 27 [28160/60000 (47%)]\tLoss: 103.443710\n",
      "Train Epoch: 27 [29440/60000 (49%)]\tLoss: 98.659256\n",
      "Train Epoch: 27 [30720/60000 (51%)]\tLoss: 103.608757\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 102.746979\n",
      "Train Epoch: 27 [33280/60000 (55%)]\tLoss: 101.826767\n",
      "Train Epoch: 27 [34560/60000 (58%)]\tLoss: 105.312103\n",
      "Train Epoch: 27 [35840/60000 (60%)]\tLoss: 103.125107\n",
      "Train Epoch: 27 [37120/60000 (62%)]\tLoss: 105.477211\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 106.065025\n",
      "Train Epoch: 27 [39680/60000 (66%)]\tLoss: 101.972450\n",
      "Train Epoch: 27 [40960/60000 (68%)]\tLoss: 103.846725\n",
      "Train Epoch: 27 [42240/60000 (70%)]\tLoss: 102.766937\n",
      "Train Epoch: 27 [43520/60000 (72%)]\tLoss: 99.877930\n",
      "Train Epoch: 27 [44800/60000 (75%)]\tLoss: 103.422012\n",
      "Train Epoch: 27 [46080/60000 (77%)]\tLoss: 103.795853\n",
      "Train Epoch: 27 [47360/60000 (79%)]\tLoss: 106.220184\n",
      "Train Epoch: 27 [48640/60000 (81%)]\tLoss: 101.094055\n",
      "Train Epoch: 27 [49920/60000 (83%)]\tLoss: 104.255371\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 106.532082\n",
      "Train Epoch: 27 [52480/60000 (87%)]\tLoss: 108.693573\n",
      "Train Epoch: 27 [53760/60000 (90%)]\tLoss: 104.132042\n",
      "Train Epoch: 27 [55040/60000 (92%)]\tLoss: 102.913643\n",
      "Train Epoch: 27 [56320/60000 (94%)]\tLoss: 104.008926\n",
      "Train Epoch: 27 [57600/60000 (96%)]\tLoss: 102.629829\n",
      "Train Epoch: 27 [58880/60000 (98%)]\tLoss: 104.294090\n",
      "====> Epoch: 27 Average loss: 103.1676\n",
      "====> Test set loss: 103.1442\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 100.491165\n",
      "Train Epoch: 28 [1280/60000 (2%)]\tLoss: 103.617340\n",
      "Train Epoch: 28 [2560/60000 (4%)]\tLoss: 103.559105\n",
      "Train Epoch: 28 [3840/60000 (6%)]\tLoss: 103.531654\n",
      "Train Epoch: 28 [5120/60000 (9%)]\tLoss: 101.802094\n",
      "Train Epoch: 28 [6400/60000 (11%)]\tLoss: 101.084412\n",
      "Train Epoch: 28 [7680/60000 (13%)]\tLoss: 100.876648\n",
      "Train Epoch: 28 [8960/60000 (15%)]\tLoss: 103.926750\n",
      "Train Epoch: 28 [10240/60000 (17%)]\tLoss: 106.242630\n",
      "Train Epoch: 28 [11520/60000 (19%)]\tLoss: 100.919037\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 105.307404\n",
      "Train Epoch: 28 [14080/60000 (23%)]\tLoss: 99.416809\n",
      "Train Epoch: 28 [15360/60000 (26%)]\tLoss: 103.840660\n",
      "Train Epoch: 28 [16640/60000 (28%)]\tLoss: 101.171860\n",
      "Train Epoch: 28 [17920/60000 (30%)]\tLoss: 104.389557\n",
      "Train Epoch: 28 [19200/60000 (32%)]\tLoss: 101.150528\n",
      "Train Epoch: 28 [20480/60000 (34%)]\tLoss: 100.102875\n",
      "Train Epoch: 28 [21760/60000 (36%)]\tLoss: 97.655296\n",
      "Train Epoch: 28 [23040/60000 (38%)]\tLoss: 107.531860\n",
      "Train Epoch: 28 [24320/60000 (41%)]\tLoss: 104.539940\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 101.765259\n",
      "Train Epoch: 28 [26880/60000 (45%)]\tLoss: 103.475159\n",
      "Train Epoch: 28 [28160/60000 (47%)]\tLoss: 102.892204\n",
      "Train Epoch: 28 [29440/60000 (49%)]\tLoss: 102.780121\n",
      "Train Epoch: 28 [30720/60000 (51%)]\tLoss: 102.906937\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 105.891006\n",
      "Train Epoch: 28 [33280/60000 (55%)]\tLoss: 102.314796\n",
      "Train Epoch: 28 [34560/60000 (58%)]\tLoss: 105.248642\n",
      "Train Epoch: 28 [35840/60000 (60%)]\tLoss: 105.990059\n",
      "Train Epoch: 28 [37120/60000 (62%)]\tLoss: 101.976196\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 104.703331\n",
      "Train Epoch: 28 [39680/60000 (66%)]\tLoss: 101.735245\n",
      "Train Epoch: 28 [40960/60000 (68%)]\tLoss: 102.429756\n",
      "Train Epoch: 28 [42240/60000 (70%)]\tLoss: 99.290848\n",
      "Train Epoch: 28 [43520/60000 (72%)]\tLoss: 101.689728\n",
      "Train Epoch: 28 [44800/60000 (75%)]\tLoss: 104.159309\n",
      "Train Epoch: 28 [46080/60000 (77%)]\tLoss: 98.829102\n",
      "Train Epoch: 28 [47360/60000 (79%)]\tLoss: 103.782532\n",
      "Train Epoch: 28 [48640/60000 (81%)]\tLoss: 103.866669\n",
      "Train Epoch: 28 [49920/60000 (83%)]\tLoss: 104.070908\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 99.853462\n",
      "Train Epoch: 28 [52480/60000 (87%)]\tLoss: 106.837105\n",
      "Train Epoch: 28 [53760/60000 (90%)]\tLoss: 101.905548\n",
      "Train Epoch: 28 [55040/60000 (92%)]\tLoss: 105.164398\n",
      "Train Epoch: 28 [56320/60000 (94%)]\tLoss: 101.988922\n",
      "Train Epoch: 28 [57600/60000 (96%)]\tLoss: 100.535278\n",
      "Train Epoch: 28 [58880/60000 (98%)]\tLoss: 100.926460\n",
      "====> Epoch: 28 Average loss: 103.1312\n",
      "====> Test set loss: 102.8821\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 101.311790\n",
      "Train Epoch: 29 [1280/60000 (2%)]\tLoss: 104.184578\n",
      "Train Epoch: 29 [2560/60000 (4%)]\tLoss: 104.820755\n",
      "Train Epoch: 29 [3840/60000 (6%)]\tLoss: 106.571777\n",
      "Train Epoch: 29 [5120/60000 (9%)]\tLoss: 103.893723\n",
      "Train Epoch: 29 [6400/60000 (11%)]\tLoss: 102.756264\n",
      "Train Epoch: 29 [7680/60000 (13%)]\tLoss: 101.613548\n",
      "Train Epoch: 29 [8960/60000 (15%)]\tLoss: 101.587578\n",
      "Train Epoch: 29 [10240/60000 (17%)]\tLoss: 102.841171\n",
      "Train Epoch: 29 [11520/60000 (19%)]\tLoss: 102.355225\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 101.512589\n",
      "Train Epoch: 29 [14080/60000 (23%)]\tLoss: 104.951752\n",
      "Train Epoch: 29 [15360/60000 (26%)]\tLoss: 106.926636\n",
      "Train Epoch: 29 [16640/60000 (28%)]\tLoss: 100.258362\n",
      "Train Epoch: 29 [17920/60000 (30%)]\tLoss: 106.091400\n",
      "Train Epoch: 29 [19200/60000 (32%)]\tLoss: 105.176895\n",
      "Train Epoch: 29 [20480/60000 (34%)]\tLoss: 102.877472\n",
      "Train Epoch: 29 [21760/60000 (36%)]\tLoss: 102.786179\n",
      "Train Epoch: 29 [23040/60000 (38%)]\tLoss: 100.242172\n",
      "Train Epoch: 29 [24320/60000 (41%)]\tLoss: 101.837906\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 103.400421\n",
      "Train Epoch: 29 [26880/60000 (45%)]\tLoss: 100.110786\n",
      "Train Epoch: 29 [28160/60000 (47%)]\tLoss: 103.265656\n",
      "Train Epoch: 29 [29440/60000 (49%)]\tLoss: 100.453468\n",
      "Train Epoch: 29 [30720/60000 (51%)]\tLoss: 106.222572\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 105.567184\n",
      "Train Epoch: 29 [33280/60000 (55%)]\tLoss: 97.965599\n",
      "Train Epoch: 29 [34560/60000 (58%)]\tLoss: 103.469910\n",
      "Train Epoch: 29 [35840/60000 (60%)]\tLoss: 101.764946\n",
      "Train Epoch: 29 [37120/60000 (62%)]\tLoss: 104.541374\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 105.880066\n",
      "Train Epoch: 29 [39680/60000 (66%)]\tLoss: 104.619446\n",
      "Train Epoch: 29 [40960/60000 (68%)]\tLoss: 106.438217\n",
      "Train Epoch: 29 [42240/60000 (70%)]\tLoss: 100.015366\n",
      "Train Epoch: 29 [43520/60000 (72%)]\tLoss: 102.104416\n",
      "Train Epoch: 29 [44800/60000 (75%)]\tLoss: 99.464478\n",
      "Train Epoch: 29 [46080/60000 (77%)]\tLoss: 103.943893\n",
      "Train Epoch: 29 [47360/60000 (79%)]\tLoss: 104.076927\n",
      "Train Epoch: 29 [48640/60000 (81%)]\tLoss: 102.092041\n",
      "Train Epoch: 29 [49920/60000 (83%)]\tLoss: 102.522430\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 104.420143\n",
      "Train Epoch: 29 [52480/60000 (87%)]\tLoss: 105.557755\n",
      "Train Epoch: 29 [53760/60000 (90%)]\tLoss: 98.896706\n",
      "Train Epoch: 29 [55040/60000 (92%)]\tLoss: 101.688393\n",
      "Train Epoch: 29 [56320/60000 (94%)]\tLoss: 101.899033\n",
      "Train Epoch: 29 [57600/60000 (96%)]\tLoss: 103.513939\n",
      "Train Epoch: 29 [58880/60000 (98%)]\tLoss: 103.297195\n",
      "====> Epoch: 29 Average loss: 103.0256\n",
      "====> Test set loss: 102.9497\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 104.532822\n",
      "Train Epoch: 30 [1280/60000 (2%)]\tLoss: 104.247559\n",
      "Train Epoch: 30 [2560/60000 (4%)]\tLoss: 106.664932\n",
      "Train Epoch: 30 [3840/60000 (6%)]\tLoss: 101.946053\n",
      "Train Epoch: 30 [5120/60000 (9%)]\tLoss: 101.057755\n",
      "Train Epoch: 30 [6400/60000 (11%)]\tLoss: 101.607605\n",
      "Train Epoch: 30 [7680/60000 (13%)]\tLoss: 100.419357\n",
      "Train Epoch: 30 [8960/60000 (15%)]\tLoss: 100.770569\n",
      "Train Epoch: 30 [10240/60000 (17%)]\tLoss: 104.449455\n",
      "Train Epoch: 30 [11520/60000 (19%)]\tLoss: 100.986588\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 99.920029\n",
      "Train Epoch: 30 [14080/60000 (23%)]\tLoss: 100.772934\n",
      "Train Epoch: 30 [15360/60000 (26%)]\tLoss: 103.599091\n",
      "Train Epoch: 30 [16640/60000 (28%)]\tLoss: 99.947968\n",
      "Train Epoch: 30 [17920/60000 (30%)]\tLoss: 100.585403\n",
      "Train Epoch: 30 [19200/60000 (32%)]\tLoss: 102.919159\n",
      "Train Epoch: 30 [20480/60000 (34%)]\tLoss: 102.824455\n",
      "Train Epoch: 30 [21760/60000 (36%)]\tLoss: 104.923019\n",
      "Train Epoch: 30 [23040/60000 (38%)]\tLoss: 100.327484\n",
      "Train Epoch: 30 [24320/60000 (41%)]\tLoss: 100.017273\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 102.525795\n",
      "Train Epoch: 30 [26880/60000 (45%)]\tLoss: 102.431999\n",
      "Train Epoch: 30 [28160/60000 (47%)]\tLoss: 103.323792\n",
      "Train Epoch: 30 [29440/60000 (49%)]\tLoss: 106.467110\n",
      "Train Epoch: 30 [30720/60000 (51%)]\tLoss: 103.277420\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 100.199715\n",
      "Train Epoch: 30 [33280/60000 (55%)]\tLoss: 101.871407\n",
      "Train Epoch: 30 [34560/60000 (58%)]\tLoss: 103.158096\n",
      "Train Epoch: 30 [35840/60000 (60%)]\tLoss: 105.721947\n",
      "Train Epoch: 30 [37120/60000 (62%)]\tLoss: 104.387505\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 107.212433\n",
      "Train Epoch: 30 [39680/60000 (66%)]\tLoss: 100.854309\n",
      "Train Epoch: 30 [40960/60000 (68%)]\tLoss: 100.988754\n",
      "Train Epoch: 30 [42240/60000 (70%)]\tLoss: 105.889450\n",
      "Train Epoch: 30 [43520/60000 (72%)]\tLoss: 105.229424\n",
      "Train Epoch: 30 [44800/60000 (75%)]\tLoss: 106.724014\n",
      "Train Epoch: 30 [46080/60000 (77%)]\tLoss: 106.778091\n",
      "Train Epoch: 30 [47360/60000 (79%)]\tLoss: 102.779541\n",
      "Train Epoch: 30 [48640/60000 (81%)]\tLoss: 103.150513\n",
      "Train Epoch: 30 [49920/60000 (83%)]\tLoss: 107.452545\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 105.600212\n",
      "Train Epoch: 30 [52480/60000 (87%)]\tLoss: 99.212173\n",
      "Train Epoch: 30 [53760/60000 (90%)]\tLoss: 102.540131\n",
      "Train Epoch: 30 [55040/60000 (92%)]\tLoss: 102.646820\n",
      "Train Epoch: 30 [56320/60000 (94%)]\tLoss: 101.157372\n",
      "Train Epoch: 30 [57600/60000 (96%)]\tLoss: 99.214951\n",
      "Train Epoch: 30 [58880/60000 (98%)]\tLoss: 101.619156\n",
      "====> Epoch: 30 Average loss: 102.9395\n",
      "====> Test set loss: 103.0697\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    avg_loss = train(epoch)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    test(epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, 20).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "                    '../../../datasets/results/VAE_MNIST/sample_' + str(epoch) + '.png')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a34064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store final sample\n",
    "save_image(sample.view(64, 1, 28, 28),\n",
    "                    '../img/week6_VAE_MNIST_sample' + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ef2b04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(train_losses, '-o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average VAE Loss\")\n",
    "plt.title(\"VAE Training Loss (MNIST)\")\n",
    "    \n",
    "\n",
    "if print_figs:\n",
    "    plt.savefig(\"../img/week6_MNIST_VAE.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffd159f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
