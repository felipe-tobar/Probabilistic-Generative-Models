{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce51feaf",
   "metadata": {},
   "source": [
    "Implementation of a CNN on MNIST\n",
    "Taken from pytorch documentation\n",
    "Taken from pytorch documentation: https://github.com/pytorch/examples/tree/main/mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fa82a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "print_figs = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "160ccb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)          # 320 params\n",
    "        x = F.relu(x)              # 0 params\n",
    "        x = self.conv2(x)          # 18,496 params\n",
    "        x = F.relu(x)              # 0 params\n",
    "        x = F.max_pool2d(x, 2)     # 0 params\n",
    "        x = self.dropout1(x)       # 0 params\n",
    "        x = torch.flatten(x, 1)    # 0 params\n",
    "        x = self.fc1(x)            # 1,179,904 params\n",
    "        x = F.relu(x)              # 0 params\n",
    "        x = self.dropout2(x)       # 0 params\n",
    "        x = self.fc2(x)            # 1,290 params\n",
    "        output = F.log_softmax(x, dim=1)  # 0 params\n",
    "        return output\n",
    "    # Total parameters = 1,200,010\n",
    "\n",
    "            \n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0   # ← added\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()   # ← added\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "    return total_loss / len(train_loader)   # ← added\n",
    "\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * accuracy))\n",
    "\n",
    "    return test_loss   # ← return validation loss instead\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "015d138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "                    help='number of epochs to train (default: 14)')\n",
    "parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                    help='learning rate (default: 1.0)')\n",
    "parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                    help='Learning rate step gamma (default: 0.7)')\n",
    "parser.add_argument('--no-accel', action='store_true',\n",
    "                    help='disables accelerator')\n",
    "parser.add_argument('--dry-run', action='store_true',\n",
    "                    help='quickly check a single pass')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save-model', action='store_true', \n",
    "                    help='For Saving the current Model')\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Standard accelerator selection\n",
    "if (not args.no_accel) and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif (not args.no_accel) and hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")   # Apple Silicon\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "use_accel = device.type != \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "test_kwargs = {'batch_size': args.test_batch_size}\n",
    "if use_accel:\n",
    "    accel_kwargs = {'num_workers': 1,\n",
    "                    'persistent_workers': True,\n",
    "                    'pin_memory': True,\n",
    "                    'shuffle': True}\n",
    "    train_kwargs.update(accel_kwargs)\n",
    "    test_kwargs.update(accel_kwargs)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                    transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b2bca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306055\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.687779\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.814345\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.603297\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.419133\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.365164\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.227459\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.528945\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.149905\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.262869\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.257235\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.256729\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.217723\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.179979\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.424954\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.136998\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.189300\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.127093\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.228486\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.075479\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.104820\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.203263\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.187634\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.253017\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.417396\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.379551\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.066247\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.155008\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.141397\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.300183\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.136400\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.112835\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.246021\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.121453\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.187617\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.115994\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.390458\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.264239\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.097774\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.044256\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.114003\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.134096\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.205856\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.096142\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.143401\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.027645\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.130980\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.237532\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.186900\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.121083\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.153155\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.134957\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.108778\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.227427\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.100002\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.082568\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.064858\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.382477\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.063086\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.035919\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.136420\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.049260\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.462722\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.314748\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.166495\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.226614\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.072409\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.074518\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.063068\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.145525\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.058435\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.321101\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.037302\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.051277\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.124395\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.091413\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.265607\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.039211\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.080938\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.137218\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.127125\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.223206\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.088159\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.030815\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.069029\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.092823\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.077239\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.220220\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.196919\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.041456\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.069727\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.084202\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.047980\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.096858\n",
      "\n",
      "Test set: Average loss: 0.0482, Accuracy: 9842/10000 (98%)\n",
      "\n",
      "Epoch 1: Train Loss = 0.1904, Val Error = 0.0482\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.058501\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.040124\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.176628\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.113677\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.070693\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.182135\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.112985\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.013388\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.312569\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.075927\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.012036\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.104732\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.035488\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.068308\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.218106\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.124784\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.158990\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.088638\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.025919\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.015980\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.095452\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.024519\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.191370\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.020534\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.035573\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.030756\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.094046\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.015895\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.116960\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.217682\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.029690\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.050674\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.117464\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.086916\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.052541\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.028793\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.081917\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.073892\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.112107\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.089076\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.119865\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.073433\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.009403\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.095786\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.022088\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.084997\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.050040\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.015255\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.034884\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.026739\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.083051\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.010171\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.165880\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.082047\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.111879\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.126804\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.032424\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.097211\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.033480\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.022258\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.102221\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.017940\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.028032\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.058303\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.074045\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.081305\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.076190\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.010145\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.050801\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.043715\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.090504\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.038057\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.064074\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.032039\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.011708\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.023763\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.010743\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.014432\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.004265\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.166756\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.021216\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.069883\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.117988\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.090234\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.027970\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.020816\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.177196\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.042543\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.015970\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.077650\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.055317\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.080158\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.019929\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.197833\n",
      "\n",
      "Test set: Average loss: 0.0333, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "Epoch 2: Train Loss = 0.0737, Val Error = 0.0333\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.017441\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.008080\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.090321\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.015821\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.052990\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.118504\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.031547\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.071978\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.023586\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.011680\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.076348\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.007330\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.005388\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.084257\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.153815\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.017031\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.089950\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.160245\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.048636\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.039896\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.007833\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.098391\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.021950\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.044400\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.019886\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.299467\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.036405\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.147501\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.017132\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.013899\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.032935\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.151772\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.004388\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.037874\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.044088\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.005587\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.020058\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.065248\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.002379\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.066546\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.160535\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.026955\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.054555\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.014290\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.005468\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.012165\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.004353\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.028393\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.024094\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.050059\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.010388\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.024733\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.003937\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.079668\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.038728\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.014641\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.021913\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.007744\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.026706\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.064117\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.039677\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.030920\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.047353\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.096329\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.096861\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.075741\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.070748\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.147450\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.023709\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.010532\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.050228\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.005269\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.091755\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.007132\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.068646\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.044672\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.008160\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.001532\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.069428\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.041521\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.005217\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.050426\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.006208\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.042015\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.007164\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.204348\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.014998\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.056262\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.003737\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.077222\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.103755\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.008404\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.026845\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.088844\n",
      "\n",
      "Test set: Average loss: 0.0320, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Epoch 3: Train Loss = 0.0529, Val Error = 0.0320\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.015811\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.036594\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.012998\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.053840\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.120999\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.122794\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.051354\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.009125\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.057073\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.022757\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.072004\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.035403\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.035688\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.029710\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.037984\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.135584\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.036890\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.120151\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.022433\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.007381\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.036756\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.005305\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.044091\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.117661\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.152125\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.040673\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.006247\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.003096\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.031601\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.094363\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.076991\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.054550\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.055414\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.018179\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.015969\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.000414\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.019726\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.009010\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.038427\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.135587\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.005236\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.005789\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.007155\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.024168\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.074896\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.062563\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.009020\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.084636\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.008171\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.006966\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.029437\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.056446\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.020615\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.024933\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.103448\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.013183\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.076073\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.026256\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.009972\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.018848\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.064724\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.003981\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.020799\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.036366\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.027040\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.008359\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.122969\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.024582\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.024767\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.020251\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.011395\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.131780\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.000896\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.010062\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.044622\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.006280\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.018696\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.201888\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.067952\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.045593\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.041511\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.027786\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.039256\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.019108\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.031350\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.174574\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.024144\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.103354\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.016435\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.173429\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.022976\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.015982\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.113860\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.028931\n",
      "\n",
      "Test set: Average loss: 0.0317, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Epoch 4: Train Loss = 0.0434, Val Error = 0.0317\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.087316\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.047982\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.005118\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.006792\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.113140\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.002706\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.033597\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.049579\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.020590\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.025648\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.057113\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.114392\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.037351\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.027084\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.011296\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.004191\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.004919\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.034588\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.075466\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.033986\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.012982\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.015659\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.001311\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.245322\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.012506\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.008080\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.013308\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.002124\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.002415\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.004332\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.026902\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.008221\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.001287\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.014570\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.006870\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.011781\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.057399\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.003682\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.093387\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.053808\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.009593\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.017112\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.043979\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.009005\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.010931\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.008782\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.002120\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.020582\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.006450\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.039053\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.003885\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.000308\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.025820\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.002143\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.014048\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.008308\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.006361\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.010823\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.002619\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.042709\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.016344\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.030193\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.012870\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.002350\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.272361\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.096335\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.003926\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.014517\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.073398\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.045754\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.080981\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.103193\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.009379\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.003115\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.036615\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.072740\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.010954\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.044040\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.027619\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.009764\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.002653\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.109087\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.013237\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.008672\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.009715\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.048568\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.027283\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.008179\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.081610\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.004466\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.008780\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.018161\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.017720\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.006236\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Epoch 5: Train Loss = 0.0348, Val Error = 0.0279\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.007285\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.009791\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.011374\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.076519\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.016896\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.013183\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.039116\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.007535\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.012179\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.011848\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.046942\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.094744\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.003689\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.021554\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.016562\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.051746\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.010819\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.021754\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.006493\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.007982\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.027138\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.018273\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.007735\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.056381\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.005696\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.021663\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.022625\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.017740\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.011762\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.017773\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.120737\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.006870\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.001873\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.053555\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.087285\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.115243\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.002799\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.010937\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.021225\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.007565\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.029575\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.057586\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.001746\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.009262\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.026520\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.025491\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.023521\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.025541\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.010797\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.009827\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.000868\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.022513\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.029261\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.032734\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.007819\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.029198\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.033609\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.012998\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.066847\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.004095\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.011482\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.022603\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.000514\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.005949\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.012415\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.005770\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.089866\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.020101\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.038264\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.010803\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.012309\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.003696\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.001372\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.003021\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.040127\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.001109\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.023118\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.041972\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.013246\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.008805\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.001952\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.042705\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.136650\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.068903\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.026694\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.045869\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.036681\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.046366\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.028872\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.002720\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.003578\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.002710\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.081042\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.026233\n",
      "\n",
      "Test set: Average loss: 0.0306, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Epoch 6: Train Loss = 0.0313, Val Error = 0.0306\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.056417\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.001880\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.045289\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.000851\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.004954\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.005449\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.001772\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.004266\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.003224\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.016024\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.043306\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.010889\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.022873\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.009348\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.044124\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.020814\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.006622\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.001101\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.008133\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.004267\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.012605\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.024926\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.006898\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.017346\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.002627\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.001415\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.017388\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.008251\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.011428\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.070125\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.041438\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.118075\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.004039\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.023962\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.026075\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.006216\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.009299\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.058065\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.012107\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.073658\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.003527\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.004213\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.008310\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.014632\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.007017\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.010013\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.018811\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.015072\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.003684\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.008902\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.002133\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.002909\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.010716\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.007107\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.006706\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.009190\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.014326\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.008675\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.209649\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.008632\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.142842\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.016047\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.017751\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.008095\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.036253\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.023904\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.008490\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.114592\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.002003\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.035481\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.022502\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.019502\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.000455\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.015053\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.007361\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.004747\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.003687\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.028965\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.004659\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.033716\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.154859\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.003608\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.010164\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.049182\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.008060\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.000785\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.002270\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.032314\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.001516\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.021065\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.003360\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.008231\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.068940\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.005162\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 9909/10000 (99%)\n",
      "\n",
      "Epoch 7: Train Loss = 0.0291, Val Error = 0.0286\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.007560\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.002798\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.040223\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.135112\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.014145\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.149602\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.054013\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.058566\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.142200\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.014908\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.004400\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.166934\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.006173\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.000783\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.002990\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.062960\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.004042\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.076477\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.002424\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.034439\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.001028\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.097935\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.050855\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.006825\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.045160\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.102831\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.033532\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.049820\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.001857\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.002291\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.008016\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.031189\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.002669\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.042279\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.006785\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.013854\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.009285\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.055596\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.002055\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.005442\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.002712\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.011090\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.004444\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.056157\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.005560\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.004136\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.004828\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.022897\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.002551\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.024735\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.075125\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.010337\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.010093\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.016287\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.122673\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.006815\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.017732\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.009852\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.060959\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.119702\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.017422\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.011754\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.039093\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.019130\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.048882\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.030216\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.051011\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.006885\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.002813\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.006952\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.121655\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.089142\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.004226\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.032173\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.008156\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.001800\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.010871\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.023591\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.019121\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.014873\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.006283\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.000700\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.008877\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.036300\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.001296\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.020458\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.039321\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.007652\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.002402\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.012231\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.008620\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.002076\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.082515\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.001601\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Epoch 8: Train Loss = 0.0278, Val Error = 0.0283\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.013328\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.055646\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.000967\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.003897\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.020129\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.064933\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.020035\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.006696\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.001935\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.042918\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.003908\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.006185\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.034138\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.015397\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.002551\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.007530\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.004032\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.109610\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.005886\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.030495\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.014474\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.057815\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.017915\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.032452\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.006988\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.004175\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.017987\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.041190\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.001438\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.004163\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.003036\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.036197\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.054806\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.010241\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.000255\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.003335\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.091593\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.013003\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.025829\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.002439\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.019194\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.034826\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.004393\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.086670\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.226161\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.002217\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.012581\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.153739\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.001876\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.006852\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.023506\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.186319\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.001874\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.004361\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.030753\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.003375\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.047142\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.014133\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.014192\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.238163\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.005529\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.019902\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.004143\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.050526\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.004330\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.100670\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.024411\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.051366\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.001574\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.042527\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.002932\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.053339\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.018871\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.005514\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.010649\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.023262\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.057499\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.013759\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.012112\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.005232\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.034927\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.010720\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.005583\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.031116\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.086711\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.020247\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.000501\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.003273\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.128849\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.022922\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.026997\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.096499\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.012198\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.003269\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 9917/10000 (99%)\n",
      "\n",
      "Epoch 9: Train Loss = 0.0280, Val Error = 0.0281\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.136966\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.004027\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.003076\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.012015\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.057788\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.014778\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.004339\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.002892\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.089916\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.022253\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.001567\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.017166\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.100917\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.007205\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.016698\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.014356\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.001909\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.020951\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.015438\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.066480\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.037187\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.012594\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.082489\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.007869\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.017838\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.000438\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.027366\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.001710\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.003261\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.032933\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.025044\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.009348\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.007817\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.050314\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.003988\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.003863\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.024607\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.005008\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.010098\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.000516\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.003831\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.002668\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.003039\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.001158\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.015021\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.065092\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.016767\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.005780\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.012816\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.009038\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.010131\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.057326\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.004374\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.025471\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.040985\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.013269\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.103046\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.006605\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.003942\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.020467\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000925\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.022852\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.091880\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.021684\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.034955\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.001767\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.003087\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.056737\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.006705\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.007373\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.004326\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.001066\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.012184\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.004679\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.064444\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.051072\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.011751\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.023047\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.014785\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.004448\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.006800\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.001877\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.006158\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.031838\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.013198\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.044801\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.099821\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.102763\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.018308\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.025806\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.002902\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.006174\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.007461\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.002906\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 9912/10000 (99%)\n",
      "\n",
      "Epoch 10: Train Loss = 0.0253, Val Error = 0.0275\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.050981\n",
      "Train Epoch: 11 [640/60000 (1%)]\tLoss: 0.012457\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 0.010190\n",
      "Train Epoch: 11 [1920/60000 (3%)]\tLoss: 0.007577\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.008143\n",
      "Train Epoch: 11 [3200/60000 (5%)]\tLoss: 0.070548\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 0.000920\n",
      "Train Epoch: 11 [4480/60000 (7%)]\tLoss: 0.029856\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.002462\n",
      "Train Epoch: 11 [5760/60000 (10%)]\tLoss: 0.010242\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.001835\n",
      "Train Epoch: 11 [7040/60000 (12%)]\tLoss: 0.007364\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.007795\n",
      "Train Epoch: 11 [8320/60000 (14%)]\tLoss: 0.011546\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 0.007224\n",
      "Train Epoch: 11 [9600/60000 (16%)]\tLoss: 0.004251\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.041761\n",
      "Train Epoch: 11 [10880/60000 (18%)]\tLoss: 0.003026\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 0.018814\n",
      "Train Epoch: 11 [12160/60000 (20%)]\tLoss: 0.064133\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.004593\n",
      "Train Epoch: 11 [13440/60000 (22%)]\tLoss: 0.031461\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 0.006000\n",
      "Train Epoch: 11 [14720/60000 (25%)]\tLoss: 0.012294\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.002721\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.012778\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 0.001666\n",
      "Train Epoch: 11 [17280/60000 (29%)]\tLoss: 0.104404\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.002534\n",
      "Train Epoch: 11 [18560/60000 (31%)]\tLoss: 0.003318\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.001649\n",
      "Train Epoch: 11 [19840/60000 (33%)]\tLoss: 0.007041\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.023479\n",
      "Train Epoch: 11 [21120/60000 (35%)]\tLoss: 0.043244\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 0.077612\n",
      "Train Epoch: 11 [22400/60000 (37%)]\tLoss: 0.010468\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.005442\n",
      "Train Epoch: 11 [23680/60000 (39%)]\tLoss: 0.009250\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 0.001904\n",
      "Train Epoch: 11 [24960/60000 (42%)]\tLoss: 0.007069\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.047027\n",
      "Train Epoch: 11 [26240/60000 (44%)]\tLoss: 0.060945\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 0.021334\n",
      "Train Epoch: 11 [27520/60000 (46%)]\tLoss: 0.013178\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.030861\n",
      "Train Epoch: 11 [28800/60000 (48%)]\tLoss: 0.009540\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 0.040568\n",
      "Train Epoch: 11 [30080/60000 (50%)]\tLoss: 0.008939\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.020621\n",
      "Train Epoch: 11 [31360/60000 (52%)]\tLoss: 0.001645\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.025905\n",
      "Train Epoch: 11 [32640/60000 (54%)]\tLoss: 0.001039\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.031909\n",
      "Train Epoch: 11 [33920/60000 (57%)]\tLoss: 0.050412\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 0.018724\n",
      "Train Epoch: 11 [35200/60000 (59%)]\tLoss: 0.000951\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.049875\n",
      "Train Epoch: 11 [36480/60000 (61%)]\tLoss: 0.001558\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 0.079030\n",
      "Train Epoch: 11 [37760/60000 (63%)]\tLoss: 0.004762\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.016617\n",
      "Train Epoch: 11 [39040/60000 (65%)]\tLoss: 0.006321\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 0.022253\n",
      "Train Epoch: 11 [40320/60000 (67%)]\tLoss: 0.003635\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.002987\n",
      "Train Epoch: 11 [41600/60000 (69%)]\tLoss: 0.006883\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 0.007451\n",
      "Train Epoch: 11 [42880/60000 (71%)]\tLoss: 0.006937\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.001553\n",
      "Train Epoch: 11 [44160/60000 (74%)]\tLoss: 0.014426\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.027660\n",
      "Train Epoch: 11 [45440/60000 (76%)]\tLoss: 0.002726\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.000342\n",
      "Train Epoch: 11 [46720/60000 (78%)]\tLoss: 0.013325\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 0.085774\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.077682\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.000693\n",
      "Train Epoch: 11 [49280/60000 (82%)]\tLoss: 0.008404\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 0.072139\n",
      "Train Epoch: 11 [50560/60000 (84%)]\tLoss: 0.118713\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.001986\n",
      "Train Epoch: 11 [51840/60000 (86%)]\tLoss: 0.038809\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 0.051263\n",
      "Train Epoch: 11 [53120/60000 (88%)]\tLoss: 0.007072\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.000896\n",
      "Train Epoch: 11 [54400/60000 (91%)]\tLoss: 0.026681\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 0.010992\n",
      "Train Epoch: 11 [55680/60000 (93%)]\tLoss: 0.023671\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.023012\n",
      "Train Epoch: 11 [56960/60000 (95%)]\tLoss: 0.035809\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.017859\n",
      "Train Epoch: 11 [58240/60000 (97%)]\tLoss: 0.004456\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.004860\n",
      "Train Epoch: 11 [59520/60000 (99%)]\tLoss: 0.160619\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 9914/10000 (99%)\n",
      "\n",
      "Epoch 11: Train Loss = 0.0248, Val Error = 0.0278\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.002841\n",
      "Train Epoch: 12 [640/60000 (1%)]\tLoss: 0.048828\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 0.020545\n",
      "Train Epoch: 12 [1920/60000 (3%)]\tLoss: 0.068664\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.018566\n",
      "Train Epoch: 12 [3200/60000 (5%)]\tLoss: 0.013105\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 0.002220\n",
      "Train Epoch: 12 [4480/60000 (7%)]\tLoss: 0.001686\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.280822\n",
      "Train Epoch: 12 [5760/60000 (10%)]\tLoss: 0.019964\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.004263\n",
      "Train Epoch: 12 [7040/60000 (12%)]\tLoss: 0.029442\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.034904\n",
      "Train Epoch: 12 [8320/60000 (14%)]\tLoss: 0.000502\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 0.026975\n",
      "Train Epoch: 12 [9600/60000 (16%)]\tLoss: 0.033923\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.027788\n",
      "Train Epoch: 12 [10880/60000 (18%)]\tLoss: 0.065528\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 0.005620\n",
      "Train Epoch: 12 [12160/60000 (20%)]\tLoss: 0.011087\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.001186\n",
      "Train Epoch: 12 [13440/60000 (22%)]\tLoss: 0.050689\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 0.055513\n",
      "Train Epoch: 12 [14720/60000 (25%)]\tLoss: 0.002553\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.007173\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.008029\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 0.007403\n",
      "Train Epoch: 12 [17280/60000 (29%)]\tLoss: 0.005916\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.025700\n",
      "Train Epoch: 12 [18560/60000 (31%)]\tLoss: 0.001903\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.049850\n",
      "Train Epoch: 12 [19840/60000 (33%)]\tLoss: 0.040975\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.007281\n",
      "Train Epoch: 12 [21120/60000 (35%)]\tLoss: 0.004127\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 0.087072\n",
      "Train Epoch: 12 [22400/60000 (37%)]\tLoss: 0.075590\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.011663\n",
      "Train Epoch: 12 [23680/60000 (39%)]\tLoss: 0.080502\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 0.003750\n",
      "Train Epoch: 12 [24960/60000 (42%)]\tLoss: 0.008025\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.027945\n",
      "Train Epoch: 12 [26240/60000 (44%)]\tLoss: 0.000467\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 0.046631\n",
      "Train Epoch: 12 [27520/60000 (46%)]\tLoss: 0.015108\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.036980\n",
      "Train Epoch: 12 [28800/60000 (48%)]\tLoss: 0.031642\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 0.002685\n",
      "Train Epoch: 12 [30080/60000 (50%)]\tLoss: 0.043349\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.005907\n",
      "Train Epoch: 12 [31360/60000 (52%)]\tLoss: 0.007115\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.003133\n",
      "Train Epoch: 12 [32640/60000 (54%)]\tLoss: 0.009218\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.010228\n",
      "Train Epoch: 12 [33920/60000 (57%)]\tLoss: 0.004721\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 0.005251\n",
      "Train Epoch: 12 [35200/60000 (59%)]\tLoss: 0.001481\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.001772\n",
      "Train Epoch: 12 [36480/60000 (61%)]\tLoss: 0.005889\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 0.010164\n",
      "Train Epoch: 12 [37760/60000 (63%)]\tLoss: 0.006356\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.003763\n",
      "Train Epoch: 12 [39040/60000 (65%)]\tLoss: 0.010300\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 0.007028\n",
      "Train Epoch: 12 [40320/60000 (67%)]\tLoss: 0.032136\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.015160\n",
      "Train Epoch: 12 [41600/60000 (69%)]\tLoss: 0.016926\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 0.003310\n",
      "Train Epoch: 12 [42880/60000 (71%)]\tLoss: 0.004383\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.003113\n",
      "Train Epoch: 12 [44160/60000 (74%)]\tLoss: 0.008151\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.014412\n",
      "Train Epoch: 12 [45440/60000 (76%)]\tLoss: 0.065843\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.039600\n",
      "Train Epoch: 12 [46720/60000 (78%)]\tLoss: 0.021022\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 0.001321\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.039141\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.019325\n",
      "Train Epoch: 12 [49280/60000 (82%)]\tLoss: 0.001741\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 0.077494\n",
      "Train Epoch: 12 [50560/60000 (84%)]\tLoss: 0.002620\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.013438\n",
      "Train Epoch: 12 [51840/60000 (86%)]\tLoss: 0.005923\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 0.016673\n",
      "Train Epoch: 12 [53120/60000 (88%)]\tLoss: 0.007164\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.036753\n",
      "Train Epoch: 12 [54400/60000 (91%)]\tLoss: 0.011616\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 0.017047\n",
      "Train Epoch: 12 [55680/60000 (93%)]\tLoss: 0.002171\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.001783\n",
      "Train Epoch: 12 [56960/60000 (95%)]\tLoss: 0.015207\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.004160\n",
      "Train Epoch: 12 [58240/60000 (97%)]\tLoss: 0.020686\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.010716\n",
      "Train Epoch: 12 [59520/60000 (99%)]\tLoss: 0.030569\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Epoch 12: Train Loss = 0.0245, Val Error = 0.0286\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.004227\n",
      "Train Epoch: 13 [640/60000 (1%)]\tLoss: 0.002216\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 0.014270\n",
      "Train Epoch: 13 [1920/60000 (3%)]\tLoss: 0.007940\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.026171\n",
      "Train Epoch: 13 [3200/60000 (5%)]\tLoss: 0.006002\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 0.003619\n",
      "Train Epoch: 13 [4480/60000 (7%)]\tLoss: 0.045420\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.041833\n",
      "Train Epoch: 13 [5760/60000 (10%)]\tLoss: 0.000912\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.014633\n",
      "Train Epoch: 13 [7040/60000 (12%)]\tLoss: 0.003191\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.012346\n",
      "Train Epoch: 13 [8320/60000 (14%)]\tLoss: 0.019760\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 0.042959\n",
      "Train Epoch: 13 [9600/60000 (16%)]\tLoss: 0.006559\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.014759\n",
      "Train Epoch: 13 [10880/60000 (18%)]\tLoss: 0.002172\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 0.005831\n",
      "Train Epoch: 13 [12160/60000 (20%)]\tLoss: 0.041160\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.012356\n",
      "Train Epoch: 13 [13440/60000 (22%)]\tLoss: 0.187203\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 0.003838\n",
      "Train Epoch: 13 [14720/60000 (25%)]\tLoss: 0.026250\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.008264\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.001329\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 0.004603\n",
      "Train Epoch: 13 [17280/60000 (29%)]\tLoss: 0.051027\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.017563\n",
      "Train Epoch: 13 [18560/60000 (31%)]\tLoss: 0.018842\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.042360\n",
      "Train Epoch: 13 [19840/60000 (33%)]\tLoss: 0.009383\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.000668\n",
      "Train Epoch: 13 [21120/60000 (35%)]\tLoss: 0.004802\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 0.001555\n",
      "Train Epoch: 13 [22400/60000 (37%)]\tLoss: 0.003047\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.011014\n",
      "Train Epoch: 13 [23680/60000 (39%)]\tLoss: 0.001733\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 0.001433\n",
      "Train Epoch: 13 [24960/60000 (42%)]\tLoss: 0.002340\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.003933\n",
      "Train Epoch: 13 [26240/60000 (44%)]\tLoss: 0.007712\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 0.005468\n",
      "Train Epoch: 13 [27520/60000 (46%)]\tLoss: 0.001796\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.019688\n",
      "Train Epoch: 13 [28800/60000 (48%)]\tLoss: 0.026326\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 0.003778\n",
      "Train Epoch: 13 [30080/60000 (50%)]\tLoss: 0.096986\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.002505\n",
      "Train Epoch: 13 [31360/60000 (52%)]\tLoss: 0.000722\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.049656\n",
      "Train Epoch: 13 [32640/60000 (54%)]\tLoss: 0.061871\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.004349\n",
      "Train Epoch: 13 [33920/60000 (57%)]\tLoss: 0.002925\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 0.028978\n",
      "Train Epoch: 13 [35200/60000 (59%)]\tLoss: 0.012015\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.055216\n",
      "Train Epoch: 13 [36480/60000 (61%)]\tLoss: 0.103639\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 0.085293\n",
      "Train Epoch: 13 [37760/60000 (63%)]\tLoss: 0.035339\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.024506\n",
      "Train Epoch: 13 [39040/60000 (65%)]\tLoss: 0.005097\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 0.014454\n",
      "Train Epoch: 13 [40320/60000 (67%)]\tLoss: 0.011692\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.026446\n",
      "Train Epoch: 13 [41600/60000 (69%)]\tLoss: 0.108381\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 0.011607\n",
      "Train Epoch: 13 [42880/60000 (71%)]\tLoss: 0.034411\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.002108\n",
      "Train Epoch: 13 [44160/60000 (74%)]\tLoss: 0.003432\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.044355\n",
      "Train Epoch: 13 [45440/60000 (76%)]\tLoss: 0.003822\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.009483\n",
      "Train Epoch: 13 [46720/60000 (78%)]\tLoss: 0.002713\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 0.101311\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.037348\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.002296\n",
      "Train Epoch: 13 [49280/60000 (82%)]\tLoss: 0.005927\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 0.023751\n",
      "Train Epoch: 13 [50560/60000 (84%)]\tLoss: 0.026328\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.074207\n",
      "Train Epoch: 13 [51840/60000 (86%)]\tLoss: 0.004882\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 0.002256\n",
      "Train Epoch: 13 [53120/60000 (88%)]\tLoss: 0.020160\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.010036\n",
      "Train Epoch: 13 [54400/60000 (91%)]\tLoss: 0.006782\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 0.013948\n",
      "Train Epoch: 13 [55680/60000 (93%)]\tLoss: 0.087702\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.014196\n",
      "Train Epoch: 13 [56960/60000 (95%)]\tLoss: 0.012891\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.015969\n",
      "Train Epoch: 13 [58240/60000 (97%)]\tLoss: 0.001469\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.007333\n",
      "Train Epoch: 13 [59520/60000 (99%)]\tLoss: 0.053355\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Epoch 13: Train Loss = 0.0255, Val Error = 0.0281\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.003701\n",
      "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.007528\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.004969\n",
      "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.004140\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.017375\n",
      "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.031013\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.002763\n",
      "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.022718\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.005663\n",
      "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.023470\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.021731\n",
      "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.003498\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.002322\n",
      "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.050893\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.000240\n",
      "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.017796\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.006000\n",
      "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.008848\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.000425\n",
      "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.060146\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.075021\n",
      "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.002351\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.001011\n",
      "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.004245\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.069107\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.012522\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.003815\n",
      "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.011026\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.010053\n",
      "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.012560\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.004104\n",
      "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.082691\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.121267\n",
      "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.007757\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.006469\n",
      "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.166954\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.013980\n",
      "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.003269\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.003068\n",
      "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.045343\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.013682\n",
      "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.004598\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.000241\n",
      "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.004238\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.010763\n",
      "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.002711\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.018014\n",
      "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.024002\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.010571\n",
      "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.008381\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.011547\n",
      "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.018125\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.003634\n",
      "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.007971\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.000466\n",
      "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.004769\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.003166\n",
      "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.006022\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.002172\n",
      "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.004251\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.027800\n",
      "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.037612\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.002058\n",
      "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.011017\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.002301\n",
      "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.017511\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.018409\n",
      "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.000614\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.011000\n",
      "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.001700\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.107190\n",
      "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.002800\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.003016\n",
      "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.003919\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.026032\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.001445\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.172965\n",
      "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.019253\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.076963\n",
      "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.000794\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.157180\n",
      "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.073637\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.012883\n",
      "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.081049\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.003117\n",
      "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.041635\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.010053\n",
      "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.020611\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.001615\n",
      "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.096399\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.035895\n",
      "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.005826\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.006098\n",
      "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.041508\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Epoch 14: Train Loss = 0.0248, Val Error = 0.0277\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "train_losses = []\n",
    "test_errors = []\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "start_time = time.perf_counter()   # ← start timer\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    avg_train_loss = train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test_error = test(model, device, test_loader)\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    test_errors.append(test_error)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}: \"\n",
    "          f\"Train Loss = {avg_train_loss:.4f}, \"\n",
    "          f\"Val Error = {test_error:.4f}\")\n",
    "\n",
    "running_time = time.perf_counter() - start_time   # ← end timer\n",
    "\n",
    "if args.save_model:\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6b2a05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(train_losses, '-o', label=\"Training loss\")\n",
    "plt.plot(test_errors, '-o', label=\"Test loss\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(f\"Training validation losses (Convolutional net, {running_time:.2f}s)\")\n",
    "plt.ylim(0.0, 0.275)  # set y-axis range\n",
    "plt.yticks(np.arange(0.025, 0.251, 0.025))  # ticks every 0.025\n",
    "\n",
    "plt.legend()\n",
    "if print_figs:\n",
    "    plt.savefig(\"../img/week6_CNN_MNIST.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b92462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
