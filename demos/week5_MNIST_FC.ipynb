{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce51feaf",
   "metadata": {},
   "source": [
    "Implementation of a CNN on MNIST\n",
    "Taken from pytorch documentation: https://github.com/pytorch/examples/tree/main/mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fa82a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "print_figs = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "160ccb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 1152)\n",
    "        self.fc2 = nn.Linear(1152, 256)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)    # 0 params\n",
    "        x = self.fc1(x)            # 904,320 params\n",
    "        x = F.relu(x)              # 0 params\n",
    "        x = self.dropout1(x)       # 0 params\n",
    "        x = self.fc2(x)            # 295,168 params\n",
    "        x = F.relu(x)              # 0 params\n",
    "        x = self.dropout2(x)       # 0 params\n",
    "        x = self.fc3(x)            # 2,570 params\n",
    "        return F.log_softmax(x, dim=1)  # 0 params\n",
    "    # Total parameters = 1,202,058\n",
    "\n",
    "            \n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0   # ← added\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()   # ← added\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "    return total_loss / len(train_loader)   # ← added\n",
    "\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * accuracy))\n",
    "\n",
    "    return test_loss   # ← return validation loss instead\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "015d138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "                    help='number of epochs to train (default: 14)')\n",
    "parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                    help='learning rate (default: 1.0)')\n",
    "parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                    help='Learning rate step gamma (default: 0.7)')\n",
    "parser.add_argument('--no-accel', action='store_true',\n",
    "                    help='disables accelerator')\n",
    "parser.add_argument('--dry-run', action='store_true',\n",
    "                    help='quickly check a single pass')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save-model', action='store_true', \n",
    "                    help='For Saving the current Model')\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Standard accelerator selection\n",
    "if (not args.no_accel) and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif (not args.no_accel) and hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")   # Apple Silicon\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "use_accel = device.type != \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "test_kwargs = {'batch_size': args.test_batch_size}\n",
    "if use_accel:\n",
    "    accel_kwargs = {'num_workers': 1,\n",
    "                    'persistent_workers': True,\n",
    "                    'pin_memory': True,\n",
    "                    'shuffle': True}\n",
    "    train_kwargs.update(accel_kwargs)\n",
    "    test_kwargs.update(accel_kwargs)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                    transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b2bca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.325222\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.310798\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.036597\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.437680\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.536125\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.327050\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.699204\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.441310\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.310115\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.397117\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.226526\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.241378\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.272799\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.131654\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.096127\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.285968\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.414601\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.362207\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.480397\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.167744\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.279180\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.191611\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.379685\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.218179\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.345497\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.178610\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.255298\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.445851\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.167312\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.153075\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.291605\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.370252\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.097001\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.178337\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.415470\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.142265\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.223739\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.133998\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.113978\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.111099\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.298605\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.201518\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.201422\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.164976\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.174979\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.312964\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.204387\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.126052\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.110725\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.131082\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.341603\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.100213\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.091021\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.300114\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.222094\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.201012\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.264392\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.222403\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.111176\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.207894\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.099269\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.088267\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.239143\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.249307\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.295285\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.404556\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.263636\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.164322\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.142041\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.039342\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.267321\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.110601\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.260059\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.141501\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.115521\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.100684\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.251092\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.110135\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.061615\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.175823\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.073225\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.324939\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.361814\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.106957\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.114449\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.230339\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.174108\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.252000\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.149696\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.267735\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.067476\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.085895\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.026578\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.028253\n",
      "\n",
      "Test set: Average loss: 0.1141, Accuracy: 9683/10000 (97%)\n",
      "\n",
      "Epoch 1: Train Loss = 0.2559, Val Error = 0.1141\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.212128\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.250768\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.028909\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.085732\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.153305\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.024802\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.009752\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.052088\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.020712\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.020501\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.378151\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.158543\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.173995\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.099138\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.090451\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.057880\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.205117\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.100537\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.112352\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.117166\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.171023\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.107687\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.100990\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.171500\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.197018\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.028482\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.033417\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.123485\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.181086\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.031121\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.274768\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.061942\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.025827\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.010506\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.045309\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.019704\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.072682\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.147992\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.095047\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.263979\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.058813\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.115458\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.196480\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.117950\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.164246\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.019155\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.042779\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.105388\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.291110\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.051642\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.136330\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.092901\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.432829\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.039456\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.069192\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.009724\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.123439\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.030460\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.113231\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.059616\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.458253\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.031033\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.062013\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.106805\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.040577\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.017956\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.097402\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.064922\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.096647\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.156470\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.094713\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.015389\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.016682\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.097036\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.056295\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.019072\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.038047\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.038035\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.050614\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.095139\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.037131\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.153623\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.339644\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.144475\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.086363\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.095289\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.017404\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.149112\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.008800\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.076603\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.096049\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.104836\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.111427\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.050870\n",
      "\n",
      "Test set: Average loss: 0.0957, Accuracy: 9745/10000 (97%)\n",
      "\n",
      "Epoch 2: Train Loss = 0.1052, Val Error = 0.0957\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.145162\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.037023\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.115547\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.139201\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.163831\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.016175\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.031708\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.034638\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.013738\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.004362\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.089932\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.227798\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.106970\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.068287\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.021726\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.063717\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.146239\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.020469\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.098414\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.048941\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.005233\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.022436\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.005197\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.034245\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.156407\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.037143\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.003862\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.125912\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.026332\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.058488\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.195004\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.028414\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.005090\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.246730\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.049095\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.023030\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.079761\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.087161\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.069401\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.014491\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.002133\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.035340\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.145429\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.032115\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.068743\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.161346\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.025528\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.024474\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.043316\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.007413\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.010832\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.150292\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.026174\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.005876\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.228622\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.079086\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.041927\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.000904\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.012298\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.006598\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.075074\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.017459\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.035952\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.091845\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.011226\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.041401\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.085012\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.014235\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.387199\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.091710\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.054630\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.121049\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.017166\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.038633\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.068411\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.029928\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.222744\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.039014\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.016649\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.033288\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.042556\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.149862\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.180640\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.027740\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.098144\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.004964\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.059608\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.079156\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.057831\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.060141\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.107371\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.049725\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.042500\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.190948\n",
      "\n",
      "Test set: Average loss: 0.0740, Accuracy: 9816/10000 (98%)\n",
      "\n",
      "Epoch 3: Train Loss = 0.0698, Val Error = 0.0740\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001899\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.098473\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.028086\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.047364\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.020712\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.046856\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.054375\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.007606\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.083222\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.009383\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.123216\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.045932\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.068500\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.062495\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.010398\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.056374\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.019755\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.181865\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.137152\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.032085\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.059562\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.093310\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.019522\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.008336\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.069285\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.023270\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.079185\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.033739\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.014161\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.133834\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.155899\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.021181\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.109217\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.103920\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.017759\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.056558\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.000116\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.133640\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.006435\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.025124\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.008834\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.004315\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.005239\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.025065\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.019048\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.063768\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.043344\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.008279\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.093552\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.138669\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.015414\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.037758\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.117914\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.167471\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.126177\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.016280\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.023912\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.005641\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.069628\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.157388\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.050092\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.009628\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.113831\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.070543\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.013135\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.010221\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.077166\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.010920\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.017754\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.006369\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.001960\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.004359\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.029810\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.003865\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.008343\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.025063\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.070105\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.001399\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.021399\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.096717\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.056424\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.006715\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.037477\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.043845\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.002424\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.081646\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.043821\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.002120\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.091528\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.106197\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.013357\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.054767\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.097415\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.033311\n",
      "\n",
      "Test set: Average loss: 0.0694, Accuracy: 9841/10000 (98%)\n",
      "\n",
      "Epoch 4: Train Loss = 0.0485, Val Error = 0.0694\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.066039\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.046634\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.016305\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.008435\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.037882\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.002689\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.038774\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.009401\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.005786\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.010317\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.074600\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.011380\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.014082\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.125139\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.016122\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.040065\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.019624\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.060222\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.049298\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.002310\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.002695\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.087438\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.261071\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.002746\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.170527\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.001270\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.080172\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.001733\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.069786\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.004385\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.005477\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.059998\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.004708\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.049288\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.169493\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.022022\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.019202\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.004096\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.077108\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.134426\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.019283\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.092396\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.002489\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.029236\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.007487\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.002160\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.008119\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.013278\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.021748\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.058765\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.009698\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.076777\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.024747\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.023704\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.004001\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.067256\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.002182\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.005205\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.004319\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.001917\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.033503\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.041855\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.126970\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.059695\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.017685\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.052636\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.024750\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.040310\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.043810\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.002003\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.030957\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.012033\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.140706\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.013253\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.009085\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.015130\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.007911\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.050438\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.060141\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.015926\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.006318\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.070291\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.002682\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.012056\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.119849\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.026968\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.031675\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.019583\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.003837\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.024039\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.005179\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.008467\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.011857\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.006230\n",
      "\n",
      "Test set: Average loss: 0.0696, Accuracy: 9834/10000 (98%)\n",
      "\n",
      "Epoch 5: Train Loss = 0.0361, Val Error = 0.0696\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.005918\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.013189\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.030523\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.016719\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.028407\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.052677\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.011250\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.008887\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.000907\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.010510\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.009423\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.003336\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.025033\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.163026\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.026657\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.006443\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.001195\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.051611\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.006268\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.006566\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.028572\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.002973\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.056544\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.021544\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.000183\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.010822\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.002722\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.006211\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.000028\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.010310\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.000311\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.090633\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.112314\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.031794\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.001644\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.033844\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.050711\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.003344\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.000458\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.004898\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.018995\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.013487\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.026993\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.023887\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.041921\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.151200\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.017533\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.003956\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.015573\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.021964\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.032296\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.051882\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.012966\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.002196\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.031321\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.000931\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.000844\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.007057\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.001164\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.004087\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.006133\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.012731\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.008704\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.000447\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.001905\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.076744\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.016544\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.064714\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.002814\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.038254\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.015056\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.027726\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.093866\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.000238\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.047238\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.063211\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.178030\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.007318\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.005043\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.003983\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.009813\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.045149\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.005830\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.034728\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.029206\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.040727\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.027627\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.019598\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.182873\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.003679\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.310894\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.031834\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.010043\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.011088\n",
      "\n",
      "Test set: Average loss: 0.0723, Accuracy: 9842/10000 (98%)\n",
      "\n",
      "Epoch 6: Train Loss = 0.0272, Val Error = 0.0723\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.010175\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.112219\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.014972\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.017757\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.028212\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.029585\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.012523\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.000821\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.005917\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.002699\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.005853\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.014556\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.085349\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.052310\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.074262\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.001438\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.005222\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.050324\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.056267\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.002175\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.025868\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.025360\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.014881\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.067530\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.002452\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.000850\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.001323\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.094900\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.035244\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.031755\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.091617\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.000612\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.001430\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.023670\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.001559\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.008919\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.086351\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.109321\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.005543\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.002852\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.001993\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.056348\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.002088\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.002431\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.002685\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.006419\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.001356\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.006321\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.016525\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.003980\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.024957\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.133370\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.002396\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.005136\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.001255\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.012524\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.012295\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.015215\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.003685\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.001439\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001438\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.004623\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.019389\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.083878\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.000837\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.000507\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.000630\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.003864\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.011403\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.007093\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.003763\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.257762\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.001949\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.055006\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.002001\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.001886\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.026243\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.003467\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.001262\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.045561\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.017143\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.011505\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.017790\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.025272\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.113219\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.021046\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.123712\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.012214\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.159586\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.002960\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.057327\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.002812\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.084988\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.037808\n",
      "\n",
      "Test set: Average loss: 0.0702, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Epoch 7: Train Loss = 0.0239, Val Error = 0.0702\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.019862\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.005931\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.071809\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.035954\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.000146\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.109221\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.002616\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.002231\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.001306\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.017802\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.028939\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.024282\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.006935\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.034376\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.007161\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.001602\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.007053\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.001712\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.003051\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.000650\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.009700\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.001343\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.008478\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.029886\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.018563\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.080518\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.028604\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.000663\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.039634\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.001004\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.006035\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.003784\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.005705\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.004499\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.000814\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.011212\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.004583\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.000182\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.001617\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.001366\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.054765\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.004568\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.013609\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.000221\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.013959\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.000577\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.031155\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.033274\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.014728\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.015732\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000876\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.092399\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.023276\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.008275\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.006379\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.028571\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.003311\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.001434\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.006790\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.002470\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.039587\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.009531\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.019611\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.032011\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.002669\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.001900\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.024422\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.001572\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.004374\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.071687\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000860\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.003454\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.000357\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.008743\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.017957\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.023163\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.108567\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.007386\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.004019\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.000501\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.009940\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.014258\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.009405\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.022499\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.087440\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.000200\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.004618\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.286580\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.055989\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.000842\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.012689\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.037821\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.030245\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.004624\n",
      "\n",
      "Test set: Average loss: 0.0710, Accuracy: 9840/10000 (98%)\n",
      "\n",
      "Epoch 8: Train Loss = 0.0204, Val Error = 0.0710\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.003754\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.055074\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.053931\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.003113\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.001341\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.000790\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.003243\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.086649\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.144762\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.004094\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.023142\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.057147\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.080928\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.010696\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.010818\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.012676\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.012150\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.008788\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.000786\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.003216\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.061044\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.008626\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.004273\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.037276\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.004136\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.034385\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.000287\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.000388\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.014409\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.002026\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.031527\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.001446\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.005794\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.004543\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.012638\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.057072\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.000624\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.004477\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.000501\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.001386\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.013940\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.001079\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.008001\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.011652\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.003112\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.003206\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.091892\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.004702\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.021438\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.000226\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.024743\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.192465\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.001239\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.001953\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.026694\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.005552\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.009942\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.001340\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.002862\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.028964\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.003182\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.006980\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.018971\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.021152\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.054976\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.002032\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.003649\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.030888\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.032717\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.003500\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.002147\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.001244\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.004602\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.051486\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.011056\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.002600\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.000464\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.000899\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.012145\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.001739\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000182\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.012141\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.045593\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.006072\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.005632\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.005153\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.006567\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.027509\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.025255\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.023263\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.034579\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.005367\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.002161\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.004818\n",
      "\n",
      "Test set: Average loss: 0.0714, Accuracy: 9843/10000 (98%)\n",
      "\n",
      "Epoch 9: Train Loss = 0.0187, Val Error = 0.0714\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.001399\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.089209\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.006239\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.014320\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.001251\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.004177\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.007898\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.001007\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.000287\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.026443\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.007722\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.031549\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.038984\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.003676\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.015259\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.000271\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.001266\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.015685\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.016390\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.130281\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.054205\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.009914\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.002796\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.064749\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.002285\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.000404\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.014074\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.006648\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.003504\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.004600\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.026825\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.005334\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.019228\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.018066\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.068966\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.001766\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.001924\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.001419\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.010506\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.004482\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.027568\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.002123\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.000312\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.043815\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.012264\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.028964\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.006274\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.020156\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.002086\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.008675\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.020807\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.001494\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.001115\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.012854\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.009463\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.001683\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.003329\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.000547\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.026691\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.017083\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.031340\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.000376\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.005886\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.006621\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.136868\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.036222\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.001108\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.013635\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.049278\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.029284\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.009211\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.005542\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.001614\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.004771\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.001647\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.001419\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.001001\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.000296\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.002198\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.024859\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.005092\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.072281\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.003228\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.012248\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.015228\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.010614\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.022999\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.001035\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.040399\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.008143\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.003255\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.002188\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.005568\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.055233\n",
      "\n",
      "Test set: Average loss: 0.0709, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Epoch 10: Train Loss = 0.0178, Val Error = 0.0709\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.017150\n",
      "Train Epoch: 11 [640/60000 (1%)]\tLoss: 0.015139\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 0.014120\n",
      "Train Epoch: 11 [1920/60000 (3%)]\tLoss: 0.049102\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.004607\n",
      "Train Epoch: 11 [3200/60000 (5%)]\tLoss: 0.005489\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 0.000291\n",
      "Train Epoch: 11 [4480/60000 (7%)]\tLoss: 0.007980\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.001491\n",
      "Train Epoch: 11 [5760/60000 (10%)]\tLoss: 0.010281\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.000922\n",
      "Train Epoch: 11 [7040/60000 (12%)]\tLoss: 0.020603\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.005471\n",
      "Train Epoch: 11 [8320/60000 (14%)]\tLoss: 0.016470\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 0.028347\n",
      "Train Epoch: 11 [9600/60000 (16%)]\tLoss: 0.006835\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.030076\n",
      "Train Epoch: 11 [10880/60000 (18%)]\tLoss: 0.004601\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 0.000975\n",
      "Train Epoch: 11 [12160/60000 (20%)]\tLoss: 0.003579\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.003605\n",
      "Train Epoch: 11 [13440/60000 (22%)]\tLoss: 0.001605\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 0.033134\n",
      "Train Epoch: 11 [14720/60000 (25%)]\tLoss: 0.015366\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.005975\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.003929\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 0.005797\n",
      "Train Epoch: 11 [17280/60000 (29%)]\tLoss: 0.037300\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.007506\n",
      "Train Epoch: 11 [18560/60000 (31%)]\tLoss: 0.001798\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.008463\n",
      "Train Epoch: 11 [19840/60000 (33%)]\tLoss: 0.107258\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.001237\n",
      "Train Epoch: 11 [21120/60000 (35%)]\tLoss: 0.001869\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 0.004978\n",
      "Train Epoch: 11 [22400/60000 (37%)]\tLoss: 0.001007\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.011645\n",
      "Train Epoch: 11 [23680/60000 (39%)]\tLoss: 0.031822\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 0.004240\n",
      "Train Epoch: 11 [24960/60000 (42%)]\tLoss: 0.132645\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.010679\n",
      "Train Epoch: 11 [26240/60000 (44%)]\tLoss: 0.009404\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 0.000298\n",
      "Train Epoch: 11 [27520/60000 (46%)]\tLoss: 0.020347\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.001384\n",
      "Train Epoch: 11 [28800/60000 (48%)]\tLoss: 0.073629\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 0.061041\n",
      "Train Epoch: 11 [30080/60000 (50%)]\tLoss: 0.001444\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.029108\n",
      "Train Epoch: 11 [31360/60000 (52%)]\tLoss: 0.010047\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.019285\n",
      "Train Epoch: 11 [32640/60000 (54%)]\tLoss: 0.029215\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.005860\n",
      "Train Epoch: 11 [33920/60000 (57%)]\tLoss: 0.019476\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 0.162027\n",
      "Train Epoch: 11 [35200/60000 (59%)]\tLoss: 0.002918\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.002628\n",
      "Train Epoch: 11 [36480/60000 (61%)]\tLoss: 0.006305\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 0.126240\n",
      "Train Epoch: 11 [37760/60000 (63%)]\tLoss: 0.001382\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.011345\n",
      "Train Epoch: 11 [39040/60000 (65%)]\tLoss: 0.000745\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 0.002591\n",
      "Train Epoch: 11 [40320/60000 (67%)]\tLoss: 0.000122\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.000718\n",
      "Train Epoch: 11 [41600/60000 (69%)]\tLoss: 0.020324\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 0.003167\n",
      "Train Epoch: 11 [42880/60000 (71%)]\tLoss: 0.057204\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.013093\n",
      "Train Epoch: 11 [44160/60000 (74%)]\tLoss: 0.007427\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.005085\n",
      "Train Epoch: 11 [45440/60000 (76%)]\tLoss: 0.080258\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.008377\n",
      "Train Epoch: 11 [46720/60000 (78%)]\tLoss: 0.001620\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 0.034964\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.021015\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.003730\n",
      "Train Epoch: 11 [49280/60000 (82%)]\tLoss: 0.000413\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 0.000018\n",
      "Train Epoch: 11 [50560/60000 (84%)]\tLoss: 0.027629\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.005042\n",
      "Train Epoch: 11 [51840/60000 (86%)]\tLoss: 0.001945\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 0.000337\n",
      "Train Epoch: 11 [53120/60000 (88%)]\tLoss: 0.024772\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.019369\n",
      "Train Epoch: 11 [54400/60000 (91%)]\tLoss: 0.000997\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 0.114372\n",
      "Train Epoch: 11 [55680/60000 (93%)]\tLoss: 0.004418\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.016294\n",
      "Train Epoch: 11 [56960/60000 (95%)]\tLoss: 0.001287\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.000756\n",
      "Train Epoch: 11 [58240/60000 (97%)]\tLoss: 0.000502\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.004020\n",
      "Train Epoch: 11 [59520/60000 (99%)]\tLoss: 0.000138\n",
      "\n",
      "Test set: Average loss: 0.0707, Accuracy: 9852/10000 (99%)\n",
      "\n",
      "Epoch 11: Train Loss = 0.0170, Val Error = 0.0707\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000997\n",
      "Train Epoch: 12 [640/60000 (1%)]\tLoss: 0.018364\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 0.119836\n",
      "Train Epoch: 12 [1920/60000 (3%)]\tLoss: 0.012560\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.026777\n",
      "Train Epoch: 12 [3200/60000 (5%)]\tLoss: 0.038710\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 0.001543\n",
      "Train Epoch: 12 [4480/60000 (7%)]\tLoss: 0.010657\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.001358\n",
      "Train Epoch: 12 [5760/60000 (10%)]\tLoss: 0.020991\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.004297\n",
      "Train Epoch: 12 [7040/60000 (12%)]\tLoss: 0.011778\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.004653\n",
      "Train Epoch: 12 [8320/60000 (14%)]\tLoss: 0.000313\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 0.001722\n",
      "Train Epoch: 12 [9600/60000 (16%)]\tLoss: 0.000579\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.007918\n",
      "Train Epoch: 12 [10880/60000 (18%)]\tLoss: 0.003826\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 0.003826\n",
      "Train Epoch: 12 [12160/60000 (20%)]\tLoss: 0.003678\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.000371\n",
      "Train Epoch: 12 [13440/60000 (22%)]\tLoss: 0.019562\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 0.000055\n",
      "Train Epoch: 12 [14720/60000 (25%)]\tLoss: 0.063821\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.008900\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.002075\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 0.003871\n",
      "Train Epoch: 12 [17280/60000 (29%)]\tLoss: 0.001539\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.002903\n",
      "Train Epoch: 12 [18560/60000 (31%)]\tLoss: 0.008488\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.001622\n",
      "Train Epoch: 12 [19840/60000 (33%)]\tLoss: 0.005397\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.064931\n",
      "Train Epoch: 12 [21120/60000 (35%)]\tLoss: 0.000744\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 0.055339\n",
      "Train Epoch: 12 [22400/60000 (37%)]\tLoss: 0.001616\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.025702\n",
      "Train Epoch: 12 [23680/60000 (39%)]\tLoss: 0.030808\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 0.054662\n",
      "Train Epoch: 12 [24960/60000 (42%)]\tLoss: 0.014576\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.006226\n",
      "Train Epoch: 12 [26240/60000 (44%)]\tLoss: 0.003349\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 0.002856\n",
      "Train Epoch: 12 [27520/60000 (46%)]\tLoss: 0.028422\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.014210\n",
      "Train Epoch: 12 [28800/60000 (48%)]\tLoss: 0.011334\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 0.031099\n",
      "Train Epoch: 12 [30080/60000 (50%)]\tLoss: 0.001197\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.000431\n",
      "Train Epoch: 12 [31360/60000 (52%)]\tLoss: 0.013236\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.009852\n",
      "Train Epoch: 12 [32640/60000 (54%)]\tLoss: 0.132999\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.001407\n",
      "Train Epoch: 12 [33920/60000 (57%)]\tLoss: 0.005095\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 0.014057\n",
      "Train Epoch: 12 [35200/60000 (59%)]\tLoss: 0.001309\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.001336\n",
      "Train Epoch: 12 [36480/60000 (61%)]\tLoss: 0.044711\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 0.001850\n",
      "Train Epoch: 12 [37760/60000 (63%)]\tLoss: 0.001261\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.026241\n",
      "Train Epoch: 12 [39040/60000 (65%)]\tLoss: 0.017019\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 0.246875\n",
      "Train Epoch: 12 [40320/60000 (67%)]\tLoss: 0.092215\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.004275\n",
      "Train Epoch: 12 [41600/60000 (69%)]\tLoss: 0.000538\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 0.002366\n",
      "Train Epoch: 12 [42880/60000 (71%)]\tLoss: 0.004567\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.030709\n",
      "Train Epoch: 12 [44160/60000 (74%)]\tLoss: 0.002515\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.007728\n",
      "Train Epoch: 12 [45440/60000 (76%)]\tLoss: 0.004230\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.032669\n",
      "Train Epoch: 12 [46720/60000 (78%)]\tLoss: 0.087333\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 0.006026\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.000668\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.006815\n",
      "Train Epoch: 12 [49280/60000 (82%)]\tLoss: 0.018933\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 0.004728\n",
      "Train Epoch: 12 [50560/60000 (84%)]\tLoss: 0.000871\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.002027\n",
      "Train Epoch: 12 [51840/60000 (86%)]\tLoss: 0.008012\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 0.004369\n",
      "Train Epoch: 12 [53120/60000 (88%)]\tLoss: 0.047981\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.067018\n",
      "Train Epoch: 12 [54400/60000 (91%)]\tLoss: 0.001213\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 0.050271\n",
      "Train Epoch: 12 [55680/60000 (93%)]\tLoss: 0.077997\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.002817\n",
      "Train Epoch: 12 [56960/60000 (95%)]\tLoss: 0.005662\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.014880\n",
      "Train Epoch: 12 [58240/60000 (97%)]\tLoss: 0.007811\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.010332\n",
      "Train Epoch: 12 [59520/60000 (99%)]\tLoss: 0.012049\n",
      "\n",
      "Test set: Average loss: 0.0712, Accuracy: 9854/10000 (99%)\n",
      "\n",
      "Epoch 12: Train Loss = 0.0165, Val Error = 0.0712\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.051707\n",
      "Train Epoch: 13 [640/60000 (1%)]\tLoss: 0.107580\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 0.068773\n",
      "Train Epoch: 13 [1920/60000 (3%)]\tLoss: 0.057506\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.003987\n",
      "Train Epoch: 13 [3200/60000 (5%)]\tLoss: 0.004158\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 0.004676\n",
      "Train Epoch: 13 [4480/60000 (7%)]\tLoss: 0.020719\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.012779\n",
      "Train Epoch: 13 [5760/60000 (10%)]\tLoss: 0.003433\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.020098\n",
      "Train Epoch: 13 [7040/60000 (12%)]\tLoss: 0.000076\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.019090\n",
      "Train Epoch: 13 [8320/60000 (14%)]\tLoss: 0.002486\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 0.002728\n",
      "Train Epoch: 13 [9600/60000 (16%)]\tLoss: 0.018372\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.002673\n",
      "Train Epoch: 13 [10880/60000 (18%)]\tLoss: 0.004577\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 0.002263\n",
      "Train Epoch: 13 [12160/60000 (20%)]\tLoss: 0.019695\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.007270\n",
      "Train Epoch: 13 [13440/60000 (22%)]\tLoss: 0.000263\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 0.000660\n",
      "Train Epoch: 13 [14720/60000 (25%)]\tLoss: 0.180674\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.004647\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.002925\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 0.030695\n",
      "Train Epoch: 13 [17280/60000 (29%)]\tLoss: 0.000240\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.000547\n",
      "Train Epoch: 13 [18560/60000 (31%)]\tLoss: 0.004136\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.014899\n",
      "Train Epoch: 13 [19840/60000 (33%)]\tLoss: 0.000127\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.013341\n",
      "Train Epoch: 13 [21120/60000 (35%)]\tLoss: 0.030198\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 0.002184\n",
      "Train Epoch: 13 [22400/60000 (37%)]\tLoss: 0.022250\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.004396\n",
      "Train Epoch: 13 [23680/60000 (39%)]\tLoss: 0.002970\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 0.015283\n",
      "Train Epoch: 13 [24960/60000 (42%)]\tLoss: 0.011563\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.043776\n",
      "Train Epoch: 13 [26240/60000 (44%)]\tLoss: 0.013652\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 0.000758\n",
      "Train Epoch: 13 [27520/60000 (46%)]\tLoss: 0.044690\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.001768\n",
      "Train Epoch: 13 [28800/60000 (48%)]\tLoss: 0.004195\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 0.000955\n",
      "Train Epoch: 13 [30080/60000 (50%)]\tLoss: 0.000891\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.002029\n",
      "Train Epoch: 13 [31360/60000 (52%)]\tLoss: 0.009002\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.024652\n",
      "Train Epoch: 13 [32640/60000 (54%)]\tLoss: 0.013481\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.005402\n",
      "Train Epoch: 13 [33920/60000 (57%)]\tLoss: 0.012332\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 0.013361\n",
      "Train Epoch: 13 [35200/60000 (59%)]\tLoss: 0.006983\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.001410\n",
      "Train Epoch: 13 [36480/60000 (61%)]\tLoss: 0.017958\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 0.005253\n",
      "Train Epoch: 13 [37760/60000 (63%)]\tLoss: 0.007866\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.004816\n",
      "Train Epoch: 13 [39040/60000 (65%)]\tLoss: 0.008463\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 0.006144\n",
      "Train Epoch: 13 [40320/60000 (67%)]\tLoss: 0.005931\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.017008\n",
      "Train Epoch: 13 [41600/60000 (69%)]\tLoss: 0.047788\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 0.000539\n",
      "Train Epoch: 13 [42880/60000 (71%)]\tLoss: 0.019289\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.015051\n",
      "Train Epoch: 13 [44160/60000 (74%)]\tLoss: 0.000871\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.248081\n",
      "Train Epoch: 13 [45440/60000 (76%)]\tLoss: 0.000130\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.024024\n",
      "Train Epoch: 13 [46720/60000 (78%)]\tLoss: 0.006031\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 0.003361\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.002259\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.002372\n",
      "Train Epoch: 13 [49280/60000 (82%)]\tLoss: 0.002086\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 0.011880\n",
      "Train Epoch: 13 [50560/60000 (84%)]\tLoss: 0.000313\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.006070\n",
      "Train Epoch: 13 [51840/60000 (86%)]\tLoss: 0.002987\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 0.018340\n",
      "Train Epoch: 13 [53120/60000 (88%)]\tLoss: 0.001268\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.000304\n",
      "Train Epoch: 13 [54400/60000 (91%)]\tLoss: 0.017662\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 0.047161\n",
      "Train Epoch: 13 [55680/60000 (93%)]\tLoss: 0.014732\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.003491\n",
      "Train Epoch: 13 [56960/60000 (95%)]\tLoss: 0.007378\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.000629\n",
      "Train Epoch: 13 [58240/60000 (97%)]\tLoss: 0.001980\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.027955\n",
      "Train Epoch: 13 [59520/60000 (99%)]\tLoss: 0.005526\n",
      "\n",
      "Test set: Average loss: 0.0715, Accuracy: 9851/10000 (99%)\n",
      "\n",
      "Epoch 13: Train Loss = 0.0159, Val Error = 0.0715\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.173584\n",
      "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.000501\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.000462\n",
      "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.011390\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.007030\n",
      "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.014780\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.019658\n",
      "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.001573\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.035815\n",
      "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.010916\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.003909\n",
      "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.000578\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.029623\n",
      "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.003080\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.007865\n",
      "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.018212\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.025583\n",
      "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.001857\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.016804\n",
      "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.006360\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.002174\n",
      "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.002861\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.007662\n",
      "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.001183\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.098571\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.000516\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.004020\n",
      "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.066787\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.004101\n",
      "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.001832\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.004839\n",
      "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.002737\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.029922\n",
      "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.018538\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.024538\n",
      "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.022615\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.015754\n",
      "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.016526\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.011813\n",
      "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.012371\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.025047\n",
      "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.005318\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.000336\n",
      "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.039346\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.010933\n",
      "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.000304\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.002150\n",
      "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.000861\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.002856\n",
      "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.009251\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.003906\n",
      "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.005309\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.001697\n",
      "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.003681\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.013713\n",
      "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.001238\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.063560\n",
      "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.083701\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.042062\n",
      "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.007502\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.001527\n",
      "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.015207\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.004039\n",
      "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.091808\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.043580\n",
      "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.017266\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.002778\n",
      "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.000639\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.000400\n",
      "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.013195\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.011732\n",
      "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.001127\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.000307\n",
      "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.007522\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.027008\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.001003\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.019154\n",
      "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.034156\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.032080\n",
      "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.002537\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.001957\n",
      "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.000449\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.011837\n",
      "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.013625\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.009869\n",
      "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.005041\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.067990\n",
      "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.003862\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.000732\n",
      "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.001994\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.018635\n",
      "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.001042\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.001266\n",
      "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.033000\n",
      "\n",
      "Test set: Average loss: 0.0716, Accuracy: 9850/10000 (98%)\n",
      "\n",
      "Epoch 14: Train Loss = 0.0141, Val Error = 0.0716\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "start_time = time.perf_counter()   # ← start timer\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    avg_train_loss = train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test_loss = test(model, device, test_loader)\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}: \"\n",
    "          f\"Train Loss = {avg_train_loss:.4f}, \"\n",
    "          f\"Val Error = {test_loss:.4f}\")\n",
    "\n",
    "running_time = time.perf_counter() - start_time   # ← end timer\n",
    "\n",
    "if args.save_model:\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6b2a05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(train_losses, '-o', label=\"Training loss\")\n",
    "plt.plot(test_losses, '-o', label=\"Test loss\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(f\"Training validation losses (Fully connected, {running_time:.2f}s)\")\n",
    "    \n",
    "plt.ylim(0.0, 0.275)  # set y-axis range\n",
    "plt.yticks(np.arange(0.025, 0.251, 0.025))  # ticks every 0.025\n",
    "plt.legend()\n",
    "\n",
    "if print_figs:\n",
    "    plt.savefig(\"../img/week6_FC_MNIST.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92dcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
